{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBFsAMcpA_OZ",
        "outputId": "e2e2b56e-4878-4f34-9230-ca00458fbfd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Open-GroundingDino'...\n",
            "remote: Enumerating objects: 177, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 177 (delta 12), reused 10 (delta 7), pack-reused 153\u001b[K\n",
            "Receiving objects: 100% (177/177), 8.74 MiB | 23.31 MiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n",
            "/content/Open-GroundingDino\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/longzw1997/Open-GroundingDino.git\n",
        "%cd Open-GroundingDino/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n",
        "%cd models/GroundingDINO/ops\n",
        "!python setup.py build install\n",
        "!python test.py\n",
        "%cd ../../.."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahc5anOYBIYn",
        "outputId": "b4373611-3c85-481a-b8e0-9ed9948c63d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (3.0.6)\n",
            "Collecting submitit (from -r requirements.txt (line 2))\n",
            "  Downloading submitit-1.5.1-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.11.4)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.4.0)\n",
            "Collecting addict (from -r requirements.txt (line 5))\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting yapf==0.40.1 (from -r requirements.txt (line 6))\n",
            "  Downloading yapf-0.40.1-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.3/250.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm (from -r requirements.txt (line 7))\n",
            "  Downloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (0.16.0+cu118)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (4.35.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (1.23.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (4.8.0.76)\n",
            "Collecting supervision==0.6.0 (from -r requirements.txt (line 13))\n",
            "  Downloading supervision-0.6.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (2.0.7)\n",
            "Requirement already satisfied: pyyaml>3.10 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (6.0.1)\n",
            "Collecting colorlog (from -r requirements.txt (line 16))\n",
            "  Downloading colorlog-6.8.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf==0.40.1->-r requirements.txt (line 6)) (7.0.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf==0.40.1->-r requirements.txt (line 6)) (4.1.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf==0.40.1->-r requirements.txt (line 6)) (2.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from supervision==0.6.0->-r requirements.txt (line 13)) (3.7.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from submitit->-r requirements.txt (line 2)) (2.2.1)\n",
            "Requirement already satisfied: typing_extensions>=3.7.4.2 in /usr/local/lib/python3.10/dist-packages (from submitit->-r requirements.txt (line 2)) (4.5.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 7)) (0.19.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 7)) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 8)) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 8)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 8)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 8)) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 8)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 8)) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 9)) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 9)) (9.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 10)) (23.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 10)) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 10)) (0.15.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 10)) (4.66.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf==0.40.1->-r requirements.txt (line 6)) (3.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.6.0->-r requirements.txt (line 13)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.6.0->-r requirements.txt (line 13)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.6.0->-r requirements.txt (line 13)) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.6.0->-r requirements.txt (line 13)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.6.0->-r requirements.txt (line 13)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->supervision==0.6.0->-r requirements.txt (line 13)) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 8)) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 9)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 9)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 9)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 9)) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->supervision==0.6.0->-r requirements.txt (line 13)) (1.16.0)\n",
            "Installing collected packages: addict, submitit, colorlog, yapf, supervision, timm\n",
            "Successfully installed addict-2.4.0 colorlog-6.8.0 submitit-1.5.1 supervision-0.6.0 timm-0.9.12 yapf-0.40.1\n",
            "/content/Open-GroundingDino/models/GroundingDINO/ops\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-cpython-310\n",
            "creating build/lib.linux-x86_64-cpython-310/modules\n",
            "copying modules/ms_deform_attn.py -> build/lib.linux-x86_64-cpython-310/modules\n",
            "copying modules/__init__.py -> build/lib.linux-x86_64-cpython-310/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/functions\n",
            "copying functions/ms_deform_attn_func.py -> build/lib.linux-x86_64-cpython-310/functions\n",
            "copying functions/__init__.py -> build/lib.linux-x86_64-cpython-310/functions\n",
            "running build_ext\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:502: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:424: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 11.8\n",
            "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "building 'MultiScaleDeformableAttention' extension\n",
            "creating build/temp.linux-x86_64-cpython-310\n",
            "creating build/temp.linux-x86_64-cpython-310/content\n",
            "creating build/temp.linux-x86_64-cpython-310/content/Open-GroundingDino\n",
            "creating build/temp.linux-x86_64-cpython-310/content/Open-GroundingDino/models\n",
            "creating build/temp.linux-x86_64-cpython-310/content/Open-GroundingDino/models/GroundingDINO\n",
            "creating build/temp.linux-x86_64-cpython-310/content/Open-GroundingDino/models/GroundingDINO/ops\n",
            "creating build/temp.linux-x86_64-cpython-310/content/Open-GroundingDino/models/GroundingDINO/ops/src\n",
            "creating build/temp.linux-x86_64-cpython-310/content/Open-GroundingDino/models/GroundingDINO/ops/src/cpu\n",
            "creating build/temp.linux-x86_64-cpython-310/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -DWITH_CUDA -I/content/Open-GroundingDino/models/GroundingDINO/ops/src -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c /content/Open-GroundingDino/models/GroundingDINO/ops/src/cpu/ms_deform_attn_cpu.cpp -o build/temp.linux-x86_64-cpython-310/content/Open-GroundingDino/models/GroundingDINO/ops/src/cpu/ms_deform_attn_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/Open-GroundingDino/models/GroundingDINO/ops/src -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c /content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu -o build/temp.linux-x86_64-cpython-310/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -std=c++17\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_im2col_cuda.cuh(261)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"q_col\"\u001b[0m was declared but never referenced\n",
            "          detected during instantiation of \u001b[01m\"void ms_deformable_im2col_cuda(cudaStream_t, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *) [with scalar_t=double]\"\u001b[0m \u001b[32m\n",
            "/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu(64): here\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_im2col_cuda.cuh(762)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"q_col\"\u001b[0m was declared but never referenced\n",
            "          detected during instantiation of \u001b[01m\"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\"\u001b[0m \u001b[32m\n",
            "/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu(134): here\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_im2col_cuda.cuh(872)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"q_col\"\u001b[0m was declared but never referenced\n",
            "          detected during instantiation of \u001b[01m\"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\"\u001b[0m \u001b[32m\n",
            "/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu(134): here\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_im2col_cuda.cuh(331)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"q_col\"\u001b[0m was declared but never referenced\n",
            "          detected during instantiation of \u001b[01m\"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\"\u001b[0m \u001b[32m\n",
            "/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu(134): here\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_im2col_cuda.cuh(436)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"q_col\"\u001b[0m was declared but never referenced\n",
            "          detected during instantiation of \u001b[01m\"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\"\u001b[0m \u001b[32m\n",
            "/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu(134): here\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_im2col_cuda.cuh(544)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"q_col\"\u001b[0m was declared but never referenced\n",
            "          detected during instantiation of \u001b[01m\"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\"\u001b[0m \u001b[32m\n",
            "/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu(134): here\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_im2col_cuda.cuh(649)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"q_col\"\u001b[0m was declared but never referenced\n",
            "          detected during instantiation of \u001b[01m\"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\"\u001b[0m \u001b[32m\n",
            "/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu(134): here\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor ms_deform_attn_cuda_forward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:34:61:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   34 |     AT_ASSERTM(value.type().is_cuda(), \"value must\u001b[01;35m\u001b[K be a CUDA t\u001b[m\u001b[Kensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:35:70:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   35 |     AT_ASSERTM(spatial_shapes.type().is_cuda(), \"s\u001b[01;35m\u001b[Kpatial_shapes must be\u001b[m\u001b[K a CUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:36:73:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   36 |     AT_ASSERTM(level_start_index.type().is_cuda(),\u001b[01;35m\u001b[K \"level_start_index must\u001b[m\u001b[K be a CUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:37:68:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   37 |     AT_ASSERTM(sampling_loc.type().is_cuda(), \"sam\u001b[01;35m\u001b[Kpling_loc must be a\u001b[m\u001b[K CUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:38:67:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   38 |     AT_ASSERTM(attn_weight.type().is_cuda(), \"attn\u001b[01;35m\u001b[K_weight must be a \u001b[m\u001b[KCUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:64:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_\u001b[01;35m\u001b[KTYPES(value.ty\u001b[m\u001b[Kpe(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                              \u001b[01;35m\u001b[K~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:64:163:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K         \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:109:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  109 | \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:64:1063:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:64:1149:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:64:1192:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:64:1225:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:64:1308:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:64:1466:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:64:2346:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:64:2432:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:64:2475:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:64:2507:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:64:2589:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:64:2746:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kstd::vector<at::Tensor> ms_deform_attn_cuda_backward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:100:61:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  100 |     AT_ASSERTM(value.type().is_cuda(), \"value must\u001b[01;35m\u001b[K be a CUDA t\u001b[m\u001b[Kensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:101:70:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  101 |     AT_ASSERTM(spatial_shapes.type().is_cuda(), \"s\u001b[01;35m\u001b[Kpatial_shapes must be\u001b[m\u001b[K a CUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:102:73:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  102 |     AT_ASSERTM(level_start_index.type().is_cuda(),\u001b[01;35m\u001b[K \"level_start_index must\u001b[m\u001b[K be a CUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:103:68:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  103 |     AT_ASSERTM(sampling_loc.type().is_cuda(), \"sam\u001b[01;35m\u001b[Kpling_loc must be a\u001b[m\u001b[K CUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:104:67:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  104 |     AT_ASSERTM(attn_weight.type().is_cuda(), \"attn\u001b[01;35m\u001b[K_weight must be a \u001b[m\u001b[KCUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:105:67:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  105 |     AT_ASSERTM(grad_output.type().is_cuda(), \"grad\u001b[01;35m\u001b[K_output must be a \u001b[m\u001b[KCUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:134:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_\u001b[01;35m\u001b[KTYPES(value.ty\u001b[m\u001b[Kpe(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                              \u001b[01;35m\u001b[K~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:134:164:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K         \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:109:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  109 | \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:134:1073:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:134:1099:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:134:1185:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:134:1228:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:134:1261:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:134:1344:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:134:1505:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:134:1589:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:134:1677:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:134:2618:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:134:2643:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:134:2729:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:134:2772:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:134:2804:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:134:2886:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:134:3046:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:134:3129:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.cu:134:3216:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -DWITH_CUDA -I/content/Open-GroundingDino/models/GroundingDINO/ops/src -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c /content/Open-GroundingDino/models/GroundingDINO/ops/src/vision.cpp -o build/temp.linux-x86_64-cpython-310/content/Open-GroundingDino/models/GroundingDINO/ops/src/vision.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "In file included from \u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/vision.cpp:11\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/ms_deform_attn.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor ms_deform_attn_forward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/ms_deform_attn.h:29:19:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   29 |     if (\u001b[01;35m\u001b[Kvalue.type()\u001b[m\u001b[K.is_cuda())\n",
            "      |         \u001b[01;35m\u001b[K~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cpu/ms_deform_attn_cpu.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/ms_deform_attn.h:13\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/vision.cpp:11\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/vision.cpp:11\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/ms_deform_attn.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kstd::vector<at::Tensor> ms_deform_attn_backward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/ms_deform_attn.h:51:19:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   51 |     if (\u001b[01;35m\u001b[Kvalue.type()\u001b[m\u001b[K.is_cuda())\n",
            "      |         \u001b[01;35m\u001b[K~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/cpu/ms_deform_attn_cpu.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/ms_deform_attn.h:13\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/Open-GroundingDino/models/GroundingDINO/ops/src/vision.cpp:11\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/content/Open-GroundingDino/models/GroundingDINO/ops/src/cpu/ms_deform_attn_cpu.o build/temp.linux-x86_64-cpython-310/content/Open-GroundingDino/models/GroundingDINO/ops/src/cuda/ms_deform_attn_cuda.o build/temp.linux-x86_64-cpython-310/content/Open-GroundingDino/models/GroundingDINO/ops/src/vision.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/MultiScaleDeformableAttention.cpython-310-x86_64-linux-gnu.so\n",
            "running install\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating MultiScaleDeformableAttention.egg-info\n",
            "writing MultiScaleDeformableAttention.egg-info/PKG-INFO\n",
            "writing dependency_links to MultiScaleDeformableAttention.egg-info/dependency_links.txt\n",
            "writing top-level names to MultiScaleDeformableAttention.egg-info/top_level.txt\n",
            "writing manifest file 'MultiScaleDeformableAttention.egg-info/SOURCES.txt'\n",
            "reading manifest file 'MultiScaleDeformableAttention.egg-info/SOURCES.txt'\n",
            "writing manifest file 'MultiScaleDeformableAttention.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-cpython-310/MultiScaleDeformableAttention.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/modules\n",
            "copying build/lib.linux-x86_64-cpython-310/modules/ms_deform_attn.py -> build/bdist.linux-x86_64/egg/modules\n",
            "copying build/lib.linux-x86_64-cpython-310/modules/__init__.py -> build/bdist.linux-x86_64/egg/modules\n",
            "creating build/bdist.linux-x86_64/egg/functions\n",
            "copying build/lib.linux-x86_64-cpython-310/functions/ms_deform_attn_func.py -> build/bdist.linux-x86_64/egg/functions\n",
            "copying build/lib.linux-x86_64-cpython-310/functions/__init__.py -> build/bdist.linux-x86_64/egg/functions\n",
            "byte-compiling build/bdist.linux-x86_64/egg/modules/ms_deform_attn.py to ms_deform_attn.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/modules/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/functions/ms_deform_attn_func.py to ms_deform_attn_func.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/functions/__init__.py to __init__.cpython-310.pyc\n",
            "creating stub loader for MultiScaleDeformableAttention.cpython-310-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/MultiScaleDeformableAttention.py to MultiScaleDeformableAttention.cpython-310.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.MultiScaleDeformableAttention.cpython-310: module references __file__\n",
            "creating dist\n",
            "creating 'dist/MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.10/dist-packages/MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg\n",
            "Extracting MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg to /usr/local/lib/python3.10/dist-packages\n",
            "Adding MultiScaleDeformableAttention 1.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg\n",
            "Processing dependencies for MultiScaleDeformableAttention==1.0\n",
            "Finished processing dependencies for MultiScaleDeformableAttention==1.0\n",
            "* True check_forward_equal_with_pytorch_double: max_abs_err 8.67e-19 max_rel_err 2.35e-16\n",
            "* True check_forward_equal_with_pytorch_float: max_abs_err 4.66e-10 max_rel_err 1.13e-07\n",
            "* True check_gradient_numerical(D=30)\n",
            "* True check_gradient_numerical(D=32)\n",
            "* True check_gradient_numerical(D=64)\n",
            "* True check_gradient_numerical(D=71)\n",
            "/content/Open-GroundingDino\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARLwcqe9UA5L",
        "outputId": "6729f3c3-7ab6-4298-da94-a4a80db75e00"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Open-GroundingDino\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy fig data to fig folder\n"
      ],
      "metadata": {
        "id": "lLXtSRphSRLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " !python3 -m zipfile -e figs/figure.zip figs/"
      ],
      "metadata": {
        "id": "h8znUcMRRZmb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py  --output_dir dino_data  --c config/cfg_odvg.py  --dataset config/datasets_od.json  --pretrain_model_path /content/drive/MyDrive/dino_data/groundingdino_swint_ogc.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjovnHdoBiF4",
        "outputId": "6d9e5ff7-4e8f-4fc6-d5b6-bc46e5c8a3e1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not using distributed mode\n",
            "Loading config file from config/cfg_odvg.py\n",
            "\u001b[32mINFO    \u001b[0m \u001b[32m2023-12-14 08:07:49,918 | \u001b[34mgit:\n",
            "  sha: 695de2f393c73ce5c917f4e2131098cb453d3374, status: has uncommited changes, branch: main\n",
            "\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[32m2023-12-14 08:07:49,919 | \u001b[34mCommand: main.py --output_dir dino_data --c config/cfg_odvg.py --dataset config/datasets_od.json --pretrain_model_path /content/drive/MyDrive/dino_data/groundingdino_swint_ogc.pth\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[32m2023-12-14 08:07:49,919 | \u001b[34mFull config saved to dino_data/config_args_all.json\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[32m2023-12-14 08:07:49,920 | \u001b[34mworld size: 1\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[32m2023-12-14 08:07:49,920 | \u001b[34mrank: 0\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[32m2023-12-14 08:07:49,920 | \u001b[34mlocal_rank: 0\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[32m2023-12-14 08:07:49,920 | \u001b[34margs: Namespace(config_file='config/cfg_odvg.py', options=None, datasets='config/datasets_od.json', remove_difficult=False, fix_size=False, output_dir='dino_data', note='', device='cuda', seed=42, resume='', pretrain_model_path='/content/drive/MyDrive/dino_data/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=7, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=40, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=True, dn_scalar=100, coco_val_path='config/Val2.json')\n",
            "\u001b[0m\n",
            "\u001b[36mDEBUG   \u001b[0m \u001b[36m2023-12-14 08:07:49,921 | \u001b[34mbuild model ... ...\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "final text_encoder_type: bert-base-uncased\n",
            "load tokenizer done.\n",
            "final text_encoder_type: bert-base-uncased\n",
            "load tokenizer done.\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[36mDEBUG   \u001b[0m \u001b[36m2023-12-14 08:07:53,378 | \u001b[34mbuild model, done.\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[32m2023-12-14 08:07:53,381 | \u001b[34mnumber of params:172249090\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[32m2023-12-14 08:07:53,385 | \u001b[34mparams before freezing:\n",
            "{\n",
            "  \"transformer.level_embed\": 1024,\n",
            "  \"transformer.encoder.layers.0.self_attn.sampling_offsets.weight\": 65536,\n",
            "  \"transformer.encoder.layers.0.self_attn.sampling_offsets.bias\": 256,\n",
            "  \"transformer.encoder.layers.0.self_attn.attention_weights.weight\": 32768,\n",
            "  \"transformer.encoder.layers.0.self_attn.attention_weights.bias\": 128,\n",
            "  \"transformer.encoder.layers.0.self_attn.value_proj.weight\": 65536,\n",
            "  \"transformer.encoder.layers.0.self_attn.value_proj.bias\": 256,\n",
            "  \"transformer.encoder.layers.0.self_attn.output_proj.weight\": 65536,\n",
            "  \"transformer.encoder.layers.0.self_attn.output_proj.bias\": 256,\n",
            "  \"transformer.encoder.layers.0.norm1.weight\": 256,\n",
            "  \"transformer.encoder.layers.0.norm1.bias\": 256,\n",
            "  \"transformer.encoder.layers.0.linear1.weight\": 524288,\n",
            "  \"transformer.encoder.layers.0.linear1.bias\": 2048,\n",
            "  \"transformer.encoder.layers.0.linear2.weight\": 524288,\n",
            "  \"transformer.encoder.layers.0.linear2.bias\": 256,\n",
            "  \"transformer.encoder.layers.0.norm2.weight\": 256,\n",
            "  \"transformer.encoder.layers.0.norm2.bias\": 256,\n",
            "  \"transformer.encoder.layers.1.self_attn.sampling_offsets.weight\": 65536,\n",
            "  \"transformer.encoder.layers.1.self_attn.sampling_offsets.bias\": 256,\n",
            "  \"transformer.encoder.layers.1.self_attn.attention_weights.weight\": 32768,\n",
            "  \"transformer.encoder.layers.1.self_attn.attention_weights.bias\": 128,\n",
            "  \"transformer.encoder.layers.1.self_attn.value_proj.weight\": 65536,\n",
            "  \"transformer.encoder.layers.1.self_attn.value_proj.bias\": 256,\n",
            "  \"transformer.encoder.layers.1.self_attn.output_proj.weight\": 65536,\n",
            "  \"transformer.encoder.layers.1.self_attn.output_proj.bias\": 256,\n",
            "  \"transformer.encoder.layers.1.norm1.weight\": 256,\n",
            "  \"transformer.encoder.layers.1.norm1.bias\": 256,\n",
            "  \"transformer.encoder.layers.1.linear1.weight\": 524288,\n",
            "  \"transformer.encoder.layers.1.linear1.bias\": 2048,\n",
            "  \"transformer.encoder.layers.1.linear2.weight\": 524288,\n",
            "  \"transformer.encoder.layers.1.linear2.bias\": 256,\n",
            "  \"transformer.encoder.layers.1.norm2.weight\": 256,\n",
            "  \"transformer.encoder.layers.1.norm2.bias\": 256,\n",
            "  \"transformer.encoder.layers.2.self_attn.sampling_offsets.weight\": 65536,\n",
            "  \"transformer.encoder.layers.2.self_attn.sampling_offsets.bias\": 256,\n",
            "  \"transformer.encoder.layers.2.self_attn.attention_weights.weight\": 32768,\n",
            "  \"transformer.encoder.layers.2.self_attn.attention_weights.bias\": 128,\n",
            "  \"transformer.encoder.layers.2.self_attn.value_proj.weight\": 65536,\n",
            "  \"transformer.encoder.layers.2.self_attn.value_proj.bias\": 256,\n",
            "  \"transformer.encoder.layers.2.self_attn.output_proj.weight\": 65536,\n",
            "  \"transformer.encoder.layers.2.self_attn.output_proj.bias\": 256,\n",
            "  \"transformer.encoder.layers.2.norm1.weight\": 256,\n",
            "  \"transformer.encoder.layers.2.norm1.bias\": 256,\n",
            "  \"transformer.encoder.layers.2.linear1.weight\": 524288,\n",
            "  \"transformer.encoder.layers.2.linear1.bias\": 2048,\n",
            "  \"transformer.encoder.layers.2.linear2.weight\": 524288,\n",
            "  \"transformer.encoder.layers.2.linear2.bias\": 256,\n",
            "  \"transformer.encoder.layers.2.norm2.weight\": 256,\n",
            "  \"transformer.encoder.layers.2.norm2.bias\": 256,\n",
            "  \"transformer.encoder.layers.3.self_attn.sampling_offsets.weight\": 65536,\n",
            "  \"transformer.encoder.layers.3.self_attn.sampling_offsets.bias\": 256,\n",
            "  \"transformer.encoder.layers.3.self_attn.attention_weights.weight\": 32768,\n",
            "  \"transformer.encoder.layers.3.self_attn.attention_weights.bias\": 128,\n",
            "  \"transformer.encoder.layers.3.self_attn.value_proj.weight\": 65536,\n",
            "  \"transformer.encoder.layers.3.self_attn.value_proj.bias\": 256,\n",
            "  \"transformer.encoder.layers.3.self_attn.output_proj.weight\": 65536,\n",
            "  \"transformer.encoder.layers.3.self_attn.output_proj.bias\": 256,\n",
            "  \"transformer.encoder.layers.3.norm1.weight\": 256,\n",
            "  \"transformer.encoder.layers.3.norm1.bias\": 256,\n",
            "  \"transformer.encoder.layers.3.linear1.weight\": 524288,\n",
            "  \"transformer.encoder.layers.3.linear1.bias\": 2048,\n",
            "  \"transformer.encoder.layers.3.linear2.weight\": 524288,\n",
            "  \"transformer.encoder.layers.3.linear2.bias\": 256,\n",
            "  \"transformer.encoder.layers.3.norm2.weight\": 256,\n",
            "  \"transformer.encoder.layers.3.norm2.bias\": 256,\n",
            "  \"transformer.encoder.layers.4.self_attn.sampling_offsets.weight\": 65536,\n",
            "  \"transformer.encoder.layers.4.self_attn.sampling_offsets.bias\": 256,\n",
            "  \"transformer.encoder.layers.4.self_attn.attention_weights.weight\": 32768,\n",
            "  \"transformer.encoder.layers.4.self_attn.attention_weights.bias\": 128,\n",
            "  \"transformer.encoder.layers.4.self_attn.value_proj.weight\": 65536,\n",
            "  \"transformer.encoder.layers.4.self_attn.value_proj.bias\": 256,\n",
            "  \"transformer.encoder.layers.4.self_attn.output_proj.weight\": 65536,\n",
            "  \"transformer.encoder.layers.4.self_attn.output_proj.bias\": 256,\n",
            "  \"transformer.encoder.layers.4.norm1.weight\": 256,\n",
            "  \"transformer.encoder.layers.4.norm1.bias\": 256,\n",
            "  \"transformer.encoder.layers.4.linear1.weight\": 524288,\n",
            "  \"transformer.encoder.layers.4.linear1.bias\": 2048,\n",
            "  \"transformer.encoder.layers.4.linear2.weight\": 524288,\n",
            "  \"transformer.encoder.layers.4.linear2.bias\": 256,\n",
            "  \"transformer.encoder.layers.4.norm2.weight\": 256,\n",
            "  \"transformer.encoder.layers.4.norm2.bias\": 256,\n",
            "  \"transformer.encoder.layers.5.self_attn.sampling_offsets.weight\": 65536,\n",
            "  \"transformer.encoder.layers.5.self_attn.sampling_offsets.bias\": 256,\n",
            "  \"transformer.encoder.layers.5.self_attn.attention_weights.weight\": 32768,\n",
            "  \"transformer.encoder.layers.5.self_attn.attention_weights.bias\": 128,\n",
            "  \"transformer.encoder.layers.5.self_attn.value_proj.weight\": 65536,\n",
            "  \"transformer.encoder.layers.5.self_attn.value_proj.bias\": 256,\n",
            "  \"transformer.encoder.layers.5.self_attn.output_proj.weight\": 65536,\n",
            "  \"transformer.encoder.layers.5.self_attn.output_proj.bias\": 256,\n",
            "  \"transformer.encoder.layers.5.norm1.weight\": 256,\n",
            "  \"transformer.encoder.layers.5.norm1.bias\": 256,\n",
            "  \"transformer.encoder.layers.5.linear1.weight\": 524288,\n",
            "  \"transformer.encoder.layers.5.linear1.bias\": 2048,\n",
            "  \"transformer.encoder.layers.5.linear2.weight\": 524288,\n",
            "  \"transformer.encoder.layers.5.linear2.bias\": 256,\n",
            "  \"transformer.encoder.layers.5.norm2.weight\": 256,\n",
            "  \"transformer.encoder.layers.5.norm2.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.0.self_attn.in_proj_weight\": 196608,\n",
            "  \"transformer.encoder.text_layers.0.self_attn.in_proj_bias\": 768,\n",
            "  \"transformer.encoder.text_layers.0.self_attn.out_proj.weight\": 65536,\n",
            "  \"transformer.encoder.text_layers.0.self_attn.out_proj.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.0.linear1.weight\": 262144,\n",
            "  \"transformer.encoder.text_layers.0.linear1.bias\": 1024,\n",
            "  \"transformer.encoder.text_layers.0.linear2.weight\": 262144,\n",
            "  \"transformer.encoder.text_layers.0.linear2.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.0.norm1.weight\": 256,\n",
            "  \"transformer.encoder.text_layers.0.norm1.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.0.norm2.weight\": 256,\n",
            "  \"transformer.encoder.text_layers.0.norm2.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.1.self_attn.in_proj_weight\": 196608,\n",
            "  \"transformer.encoder.text_layers.1.self_attn.in_proj_bias\": 768,\n",
            "  \"transformer.encoder.text_layers.1.self_attn.out_proj.weight\": 65536,\n",
            "  \"transformer.encoder.text_layers.1.self_attn.out_proj.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.1.linear1.weight\": 262144,\n",
            "  \"transformer.encoder.text_layers.1.linear1.bias\": 1024,\n",
            "  \"transformer.encoder.text_layers.1.linear2.weight\": 262144,\n",
            "  \"transformer.encoder.text_layers.1.linear2.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.1.norm1.weight\": 256,\n",
            "  \"transformer.encoder.text_layers.1.norm1.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.1.norm2.weight\": 256,\n",
            "  \"transformer.encoder.text_layers.1.norm2.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.2.self_attn.in_proj_weight\": 196608,\n",
            "  \"transformer.encoder.text_layers.2.self_attn.in_proj_bias\": 768,\n",
            "  \"transformer.encoder.text_layers.2.self_attn.out_proj.weight\": 65536,\n",
            "  \"transformer.encoder.text_layers.2.self_attn.out_proj.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.2.linear1.weight\": 262144,\n",
            "  \"transformer.encoder.text_layers.2.linear1.bias\": 1024,\n",
            "  \"transformer.encoder.text_layers.2.linear2.weight\": 262144,\n",
            "  \"transformer.encoder.text_layers.2.linear2.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.2.norm1.weight\": 256,\n",
            "  \"transformer.encoder.text_layers.2.norm1.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.2.norm2.weight\": 256,\n",
            "  \"transformer.encoder.text_layers.2.norm2.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.3.self_attn.in_proj_weight\": 196608,\n",
            "  \"transformer.encoder.text_layers.3.self_attn.in_proj_bias\": 768,\n",
            "  \"transformer.encoder.text_layers.3.self_attn.out_proj.weight\": 65536,\n",
            "  \"transformer.encoder.text_layers.3.self_attn.out_proj.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.3.linear1.weight\": 262144,\n",
            "  \"transformer.encoder.text_layers.3.linear1.bias\": 1024,\n",
            "  \"transformer.encoder.text_layers.3.linear2.weight\": 262144,\n",
            "  \"transformer.encoder.text_layers.3.linear2.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.3.norm1.weight\": 256,\n",
            "  \"transformer.encoder.text_layers.3.norm1.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.3.norm2.weight\": 256,\n",
            "  \"transformer.encoder.text_layers.3.norm2.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.4.self_attn.in_proj_weight\": 196608,\n",
            "  \"transformer.encoder.text_layers.4.self_attn.in_proj_bias\": 768,\n",
            "  \"transformer.encoder.text_layers.4.self_attn.out_proj.weight\": 65536,\n",
            "  \"transformer.encoder.text_layers.4.self_attn.out_proj.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.4.linear1.weight\": 262144,\n",
            "  \"transformer.encoder.text_layers.4.linear1.bias\": 1024,\n",
            "  \"transformer.encoder.text_layers.4.linear2.weight\": 262144,\n",
            "  \"transformer.encoder.text_layers.4.linear2.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.4.norm1.weight\": 256,\n",
            "  \"transformer.encoder.text_layers.4.norm1.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.4.norm2.weight\": 256,\n",
            "  \"transformer.encoder.text_layers.4.norm2.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.5.self_attn.in_proj_weight\": 196608,\n",
            "  \"transformer.encoder.text_layers.5.self_attn.in_proj_bias\": 768,\n",
            "  \"transformer.encoder.text_layers.5.self_attn.out_proj.weight\": 65536,\n",
            "  \"transformer.encoder.text_layers.5.self_attn.out_proj.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.5.linear1.weight\": 262144,\n",
            "  \"transformer.encoder.text_layers.5.linear1.bias\": 1024,\n",
            "  \"transformer.encoder.text_layers.5.linear2.weight\": 262144,\n",
            "  \"transformer.encoder.text_layers.5.linear2.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.5.norm1.weight\": 256,\n",
            "  \"transformer.encoder.text_layers.5.norm1.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.5.norm2.weight\": 256,\n",
            "  \"transformer.encoder.text_layers.5.norm2.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.0.gamma_v\": 256,\n",
            "  \"transformer.encoder.fusion_layers.0.gamma_l\": 256,\n",
            "  \"transformer.encoder.fusion_layers.0.layer_norm_v.weight\": 256,\n",
            "  \"transformer.encoder.fusion_layers.0.layer_norm_v.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.0.layer_norm_l.weight\": 256,\n",
            "  \"transformer.encoder.fusion_layers.0.layer_norm_l.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.0.attn.v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.0.attn.v_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.0.attn.l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.0.attn.l_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.0.attn.values_v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.0.attn.values_v_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.0.attn.values_l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.0.attn.values_l_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.0.attn.out_v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.0.attn.out_v_proj.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.0.attn.out_l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.0.attn.out_l_proj.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.1.gamma_v\": 256,\n",
            "  \"transformer.encoder.fusion_layers.1.gamma_l\": 256,\n",
            "  \"transformer.encoder.fusion_layers.1.layer_norm_v.weight\": 256,\n",
            "  \"transformer.encoder.fusion_layers.1.layer_norm_v.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.1.layer_norm_l.weight\": 256,\n",
            "  \"transformer.encoder.fusion_layers.1.layer_norm_l.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.1.attn.v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.1.attn.v_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.1.attn.l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.1.attn.l_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.1.attn.values_v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.1.attn.values_v_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.1.attn.values_l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.1.attn.values_l_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.1.attn.out_v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.1.attn.out_v_proj.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.1.attn.out_l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.1.attn.out_l_proj.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.2.gamma_v\": 256,\n",
            "  \"transformer.encoder.fusion_layers.2.gamma_l\": 256,\n",
            "  \"transformer.encoder.fusion_layers.2.layer_norm_v.weight\": 256,\n",
            "  \"transformer.encoder.fusion_layers.2.layer_norm_v.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.2.layer_norm_l.weight\": 256,\n",
            "  \"transformer.encoder.fusion_layers.2.layer_norm_l.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.2.attn.v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.2.attn.v_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.2.attn.l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.2.attn.l_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.2.attn.values_v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.2.attn.values_v_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.2.attn.values_l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.2.attn.values_l_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.2.attn.out_v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.2.attn.out_v_proj.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.2.attn.out_l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.2.attn.out_l_proj.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.3.gamma_v\": 256,\n",
            "  \"transformer.encoder.fusion_layers.3.gamma_l\": 256,\n",
            "  \"transformer.encoder.fusion_layers.3.layer_norm_v.weight\": 256,\n",
            "  \"transformer.encoder.fusion_layers.3.layer_norm_v.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.3.layer_norm_l.weight\": 256,\n",
            "  \"transformer.encoder.fusion_layers.3.layer_norm_l.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.3.attn.v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.3.attn.v_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.3.attn.l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.3.attn.l_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.3.attn.values_v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.3.attn.values_v_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.3.attn.values_l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.3.attn.values_l_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.3.attn.out_v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.3.attn.out_v_proj.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.3.attn.out_l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.3.attn.out_l_proj.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.4.gamma_v\": 256,\n",
            "  \"transformer.encoder.fusion_layers.4.gamma_l\": 256,\n",
            "  \"transformer.encoder.fusion_layers.4.layer_norm_v.weight\": 256,\n",
            "  \"transformer.encoder.fusion_layers.4.layer_norm_v.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.4.layer_norm_l.weight\": 256,\n",
            "  \"transformer.encoder.fusion_layers.4.layer_norm_l.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.4.attn.v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.4.attn.v_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.4.attn.l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.4.attn.l_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.4.attn.values_v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.4.attn.values_v_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.4.attn.values_l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.4.attn.values_l_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.4.attn.out_v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.4.attn.out_v_proj.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.4.attn.out_l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.4.attn.out_l_proj.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.5.gamma_v\": 256,\n",
            "  \"transformer.encoder.fusion_layers.5.gamma_l\": 256,\n",
            "  \"transformer.encoder.fusion_layers.5.layer_norm_v.weight\": 256,\n",
            "  \"transformer.encoder.fusion_layers.5.layer_norm_v.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.5.layer_norm_l.weight\": 256,\n",
            "  \"transformer.encoder.fusion_layers.5.layer_norm_l.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.5.attn.v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.5.attn.v_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.5.attn.l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.5.attn.l_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.5.attn.values_v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.5.attn.values_v_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.5.attn.values_l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.5.attn.values_l_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.5.attn.out_v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.5.attn.out_v_proj.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.5.attn.out_l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.5.attn.out_l_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.0.cross_attn.sampling_offsets.weight\": 65536,\n",
            "  \"transformer.decoder.layers.0.cross_attn.sampling_offsets.bias\": 256,\n",
            "  \"transformer.decoder.layers.0.cross_attn.attention_weights.weight\": 32768,\n",
            "  \"transformer.decoder.layers.0.cross_attn.attention_weights.bias\": 128,\n",
            "  \"transformer.decoder.layers.0.cross_attn.value_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.0.cross_attn.value_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.0.cross_attn.output_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.0.cross_attn.output_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.0.norm1.weight\": 256,\n",
            "  \"transformer.decoder.layers.0.norm1.bias\": 256,\n",
            "  \"transformer.decoder.layers.0.ca_text.in_proj_weight\": 196608,\n",
            "  \"transformer.decoder.layers.0.ca_text.in_proj_bias\": 768,\n",
            "  \"transformer.decoder.layers.0.ca_text.out_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.0.ca_text.out_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.0.catext_norm.weight\": 256,\n",
            "  \"transformer.decoder.layers.0.catext_norm.bias\": 256,\n",
            "  \"transformer.decoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
            "  \"transformer.decoder.layers.0.self_attn.in_proj_bias\": 768,\n",
            "  \"transformer.decoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.0.self_attn.out_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.0.norm2.weight\": 256,\n",
            "  \"transformer.decoder.layers.0.norm2.bias\": 256,\n",
            "  \"transformer.decoder.layers.0.linear1.weight\": 524288,\n",
            "  \"transformer.decoder.layers.0.linear1.bias\": 2048,\n",
            "  \"transformer.decoder.layers.0.linear2.weight\": 524288,\n",
            "  \"transformer.decoder.layers.0.linear2.bias\": 256,\n",
            "  \"transformer.decoder.layers.0.norm3.weight\": 256,\n",
            "  \"transformer.decoder.layers.0.norm3.bias\": 256,\n",
            "  \"transformer.decoder.layers.1.cross_attn.sampling_offsets.weight\": 65536,\n",
            "  \"transformer.decoder.layers.1.cross_attn.sampling_offsets.bias\": 256,\n",
            "  \"transformer.decoder.layers.1.cross_attn.attention_weights.weight\": 32768,\n",
            "  \"transformer.decoder.layers.1.cross_attn.attention_weights.bias\": 128,\n",
            "  \"transformer.decoder.layers.1.cross_attn.value_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.1.cross_attn.value_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.1.cross_attn.output_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.1.cross_attn.output_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.1.norm1.weight\": 256,\n",
            "  \"transformer.decoder.layers.1.norm1.bias\": 256,\n",
            "  \"transformer.decoder.layers.1.ca_text.in_proj_weight\": 196608,\n",
            "  \"transformer.decoder.layers.1.ca_text.in_proj_bias\": 768,\n",
            "  \"transformer.decoder.layers.1.ca_text.out_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.1.ca_text.out_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.1.catext_norm.weight\": 256,\n",
            "  \"transformer.decoder.layers.1.catext_norm.bias\": 256,\n",
            "  \"transformer.decoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
            "  \"transformer.decoder.layers.1.self_attn.in_proj_bias\": 768,\n",
            "  \"transformer.decoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.1.self_attn.out_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.1.norm2.weight\": 256,\n",
            "  \"transformer.decoder.layers.1.norm2.bias\": 256,\n",
            "  \"transformer.decoder.layers.1.linear1.weight\": 524288,\n",
            "  \"transformer.decoder.layers.1.linear1.bias\": 2048,\n",
            "  \"transformer.decoder.layers.1.linear2.weight\": 524288,\n",
            "  \"transformer.decoder.layers.1.linear2.bias\": 256,\n",
            "  \"transformer.decoder.layers.1.norm3.weight\": 256,\n",
            "  \"transformer.decoder.layers.1.norm3.bias\": 256,\n",
            "  \"transformer.decoder.layers.2.cross_attn.sampling_offsets.weight\": 65536,\n",
            "  \"transformer.decoder.layers.2.cross_attn.sampling_offsets.bias\": 256,\n",
            "  \"transformer.decoder.layers.2.cross_attn.attention_weights.weight\": 32768,\n",
            "  \"transformer.decoder.layers.2.cross_attn.attention_weights.bias\": 128,\n",
            "  \"transformer.decoder.layers.2.cross_attn.value_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.2.cross_attn.value_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.2.cross_attn.output_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.2.cross_attn.output_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.2.norm1.weight\": 256,\n",
            "  \"transformer.decoder.layers.2.norm1.bias\": 256,\n",
            "  \"transformer.decoder.layers.2.ca_text.in_proj_weight\": 196608,\n",
            "  \"transformer.decoder.layers.2.ca_text.in_proj_bias\": 768,\n",
            "  \"transformer.decoder.layers.2.ca_text.out_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.2.ca_text.out_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.2.catext_norm.weight\": 256,\n",
            "  \"transformer.decoder.layers.2.catext_norm.bias\": 256,\n",
            "  \"transformer.decoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
            "  \"transformer.decoder.layers.2.self_attn.in_proj_bias\": 768,\n",
            "  \"transformer.decoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.2.self_attn.out_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.2.norm2.weight\": 256,\n",
            "  \"transformer.decoder.layers.2.norm2.bias\": 256,\n",
            "  \"transformer.decoder.layers.2.linear1.weight\": 524288,\n",
            "  \"transformer.decoder.layers.2.linear1.bias\": 2048,\n",
            "  \"transformer.decoder.layers.2.linear2.weight\": 524288,\n",
            "  \"transformer.decoder.layers.2.linear2.bias\": 256,\n",
            "  \"transformer.decoder.layers.2.norm3.weight\": 256,\n",
            "  \"transformer.decoder.layers.2.norm3.bias\": 256,\n",
            "  \"transformer.decoder.layers.3.cross_attn.sampling_offsets.weight\": 65536,\n",
            "  \"transformer.decoder.layers.3.cross_attn.sampling_offsets.bias\": 256,\n",
            "  \"transformer.decoder.layers.3.cross_attn.attention_weights.weight\": 32768,\n",
            "  \"transformer.decoder.layers.3.cross_attn.attention_weights.bias\": 128,\n",
            "  \"transformer.decoder.layers.3.cross_attn.value_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.3.cross_attn.value_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.3.cross_attn.output_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.3.cross_attn.output_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.3.norm1.weight\": 256,\n",
            "  \"transformer.decoder.layers.3.norm1.bias\": 256,\n",
            "  \"transformer.decoder.layers.3.ca_text.in_proj_weight\": 196608,\n",
            "  \"transformer.decoder.layers.3.ca_text.in_proj_bias\": 768,\n",
            "  \"transformer.decoder.layers.3.ca_text.out_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.3.ca_text.out_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.3.catext_norm.weight\": 256,\n",
            "  \"transformer.decoder.layers.3.catext_norm.bias\": 256,\n",
            "  \"transformer.decoder.layers.3.self_attn.in_proj_weight\": 196608,\n",
            "  \"transformer.decoder.layers.3.self_attn.in_proj_bias\": 768,\n",
            "  \"transformer.decoder.layers.3.self_attn.out_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.3.self_attn.out_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.3.norm2.weight\": 256,\n",
            "  \"transformer.decoder.layers.3.norm2.bias\": 256,\n",
            "  \"transformer.decoder.layers.3.linear1.weight\": 524288,\n",
            "  \"transformer.decoder.layers.3.linear1.bias\": 2048,\n",
            "  \"transformer.decoder.layers.3.linear2.weight\": 524288,\n",
            "  \"transformer.decoder.layers.3.linear2.bias\": 256,\n",
            "  \"transformer.decoder.layers.3.norm3.weight\": 256,\n",
            "  \"transformer.decoder.layers.3.norm3.bias\": 256,\n",
            "  \"transformer.decoder.layers.4.cross_attn.sampling_offsets.weight\": 65536,\n",
            "  \"transformer.decoder.layers.4.cross_attn.sampling_offsets.bias\": 256,\n",
            "  \"transformer.decoder.layers.4.cross_attn.attention_weights.weight\": 32768,\n",
            "  \"transformer.decoder.layers.4.cross_attn.attention_weights.bias\": 128,\n",
            "  \"transformer.decoder.layers.4.cross_attn.value_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.4.cross_attn.value_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.4.cross_attn.output_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.4.cross_attn.output_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.4.norm1.weight\": 256,\n",
            "  \"transformer.decoder.layers.4.norm1.bias\": 256,\n",
            "  \"transformer.decoder.layers.4.ca_text.in_proj_weight\": 196608,\n",
            "  \"transformer.decoder.layers.4.ca_text.in_proj_bias\": 768,\n",
            "  \"transformer.decoder.layers.4.ca_text.out_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.4.ca_text.out_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.4.catext_norm.weight\": 256,\n",
            "  \"transformer.decoder.layers.4.catext_norm.bias\": 256,\n",
            "  \"transformer.decoder.layers.4.self_attn.in_proj_weight\": 196608,\n",
            "  \"transformer.decoder.layers.4.self_attn.in_proj_bias\": 768,\n",
            "  \"transformer.decoder.layers.4.self_attn.out_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.4.self_attn.out_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.4.norm2.weight\": 256,\n",
            "  \"transformer.decoder.layers.4.norm2.bias\": 256,\n",
            "  \"transformer.decoder.layers.4.linear1.weight\": 524288,\n",
            "  \"transformer.decoder.layers.4.linear1.bias\": 2048,\n",
            "  \"transformer.decoder.layers.4.linear2.weight\": 524288,\n",
            "  \"transformer.decoder.layers.4.linear2.bias\": 256,\n",
            "  \"transformer.decoder.layers.4.norm3.weight\": 256,\n",
            "  \"transformer.decoder.layers.4.norm3.bias\": 256,\n",
            "  \"transformer.decoder.layers.5.cross_attn.sampling_offsets.weight\": 65536,\n",
            "  \"transformer.decoder.layers.5.cross_attn.sampling_offsets.bias\": 256,\n",
            "  \"transformer.decoder.layers.5.cross_attn.attention_weights.weight\": 32768,\n",
            "  \"transformer.decoder.layers.5.cross_attn.attention_weights.bias\": 128,\n",
            "  \"transformer.decoder.layers.5.cross_attn.value_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.5.cross_attn.value_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.5.cross_attn.output_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.5.cross_attn.output_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.5.norm1.weight\": 256,\n",
            "  \"transformer.decoder.layers.5.norm1.bias\": 256,\n",
            "  \"transformer.decoder.layers.5.ca_text.in_proj_weight\": 196608,\n",
            "  \"transformer.decoder.layers.5.ca_text.in_proj_bias\": 768,\n",
            "  \"transformer.decoder.layers.5.ca_text.out_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.5.ca_text.out_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.5.catext_norm.weight\": 256,\n",
            "  \"transformer.decoder.layers.5.catext_norm.bias\": 256,\n",
            "  \"transformer.decoder.layers.5.self_attn.in_proj_weight\": 196608,\n",
            "  \"transformer.decoder.layers.5.self_attn.in_proj_bias\": 768,\n",
            "  \"transformer.decoder.layers.5.self_attn.out_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.5.self_attn.out_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.5.norm2.weight\": 256,\n",
            "  \"transformer.decoder.layers.5.norm2.bias\": 256,\n",
            "  \"transformer.decoder.layers.5.linear1.weight\": 524288,\n",
            "  \"transformer.decoder.layers.5.linear1.bias\": 2048,\n",
            "  \"transformer.decoder.layers.5.linear2.weight\": 524288,\n",
            "  \"transformer.decoder.layers.5.linear2.bias\": 256,\n",
            "  \"transformer.decoder.layers.5.norm3.weight\": 256,\n",
            "  \"transformer.decoder.layers.5.norm3.bias\": 256,\n",
            "  \"transformer.decoder.norm.weight\": 256,\n",
            "  \"transformer.decoder.norm.bias\": 256,\n",
            "  \"transformer.decoder.ref_point_head.layers.0.weight\": 131072,\n",
            "  \"transformer.decoder.ref_point_head.layers.0.bias\": 256,\n",
            "  \"transformer.decoder.ref_point_head.layers.1.weight\": 65536,\n",
            "  \"transformer.decoder.ref_point_head.layers.1.bias\": 256,\n",
            "  \"transformer.decoder.bbox_embed.0.layers.0.weight\": 65536,\n",
            "  \"transformer.decoder.bbox_embed.0.layers.0.bias\": 256,\n",
            "  \"transformer.decoder.bbox_embed.0.layers.1.weight\": 65536,\n",
            "  \"transformer.decoder.bbox_embed.0.layers.1.bias\": 256,\n",
            "  \"transformer.decoder.bbox_embed.0.layers.2.weight\": 1024,\n",
            "  \"transformer.decoder.bbox_embed.0.layers.2.bias\": 4,\n",
            "  \"transformer.tgt_embed.weight\": 230400,\n",
            "  \"transformer.enc_output.weight\": 65536,\n",
            "  \"transformer.enc_output.bias\": 256,\n",
            "  \"transformer.enc_output_norm.weight\": 256,\n",
            "  \"transformer.enc_output_norm.bias\": 256,\n",
            "  \"transformer.enc_out_bbox_embed.layers.0.weight\": 65536,\n",
            "  \"transformer.enc_out_bbox_embed.layers.0.bias\": 256,\n",
            "  \"transformer.enc_out_bbox_embed.layers.1.weight\": 65536,\n",
            "  \"transformer.enc_out_bbox_embed.layers.1.bias\": 256,\n",
            "  \"transformer.enc_out_bbox_embed.layers.2.weight\": 1024,\n",
            "  \"transformer.enc_out_bbox_embed.layers.2.bias\": 4,\n",
            "  \"bert.embeddings.word_embeddings.weight\": 23440896,\n",
            "  \"bert.embeddings.position_embeddings.weight\": 393216,\n",
            "  \"bert.embeddings.token_type_embeddings.weight\": 1536,\n",
            "  \"bert.embeddings.LayerNorm.weight\": 768,\n",
            "  \"bert.embeddings.LayerNorm.bias\": 768,\n",
            "  \"bert.encoder.layer.0.attention.self.query.weight\": 589824,\n",
            "  \"bert.encoder.layer.0.attention.self.query.bias\": 768,\n",
            "  \"bert.encoder.layer.0.attention.self.key.weight\": 589824,\n",
            "  \"bert.encoder.layer.0.attention.self.key.bias\": 768,\n",
            "  \"bert.encoder.layer.0.attention.self.value.weight\": 589824,\n",
            "  \"bert.encoder.layer.0.attention.self.value.bias\": 768,\n",
            "  \"bert.encoder.layer.0.attention.output.dense.weight\": 589824,\n",
            "  \"bert.encoder.layer.0.attention.output.dense.bias\": 768,\n",
            "  \"bert.encoder.layer.0.attention.output.LayerNorm.weight\": 768,\n",
            "  \"bert.encoder.layer.0.attention.output.LayerNorm.bias\": 768,\n",
            "  \"bert.encoder.layer.0.intermediate.dense.weight\": 2359296,\n",
            "  \"bert.encoder.layer.0.intermediate.dense.bias\": 3072,\n",
            "  \"bert.encoder.layer.0.output.dense.weight\": 2359296,\n",
            "  \"bert.encoder.layer.0.output.dense.bias\": 768,\n",
            "  \"bert.encoder.layer.0.output.LayerNorm.weight\": 768,\n",
            "  \"bert.encoder.layer.0.output.LayerNorm.bias\": 768,\n",
            "  \"bert.encoder.layer.1.attention.self.query.weight\": 589824,\n",
            "  \"bert.encoder.layer.1.attention.self.query.bias\": 768,\n",
            "  \"bert.encoder.layer.1.attention.self.key.weight\": 589824,\n",
            "  \"bert.encoder.layer.1.attention.self.key.bias\": 768,\n",
            "  \"bert.encoder.layer.1.attention.self.value.weight\": 589824,\n",
            "  \"bert.encoder.layer.1.attention.self.value.bias\": 768,\n",
            "  \"bert.encoder.layer.1.attention.output.dense.weight\": 589824,\n",
            "  \"bert.encoder.layer.1.attention.output.dense.bias\": 768,\n",
            "  \"bert.encoder.layer.1.attention.output.LayerNorm.weight\": 768,\n",
            "  \"bert.encoder.layer.1.attention.output.LayerNorm.bias\": 768,\n",
            "  \"bert.encoder.layer.1.intermediate.dense.weight\": 2359296,\n",
            "  \"bert.encoder.layer.1.intermediate.dense.bias\": 3072,\n",
            "  \"bert.encoder.layer.1.output.dense.weight\": 2359296,\n",
            "  \"bert.encoder.layer.1.output.dense.bias\": 768,\n",
            "  \"bert.encoder.layer.1.output.LayerNorm.weight\": 768,\n",
            "  \"bert.encoder.layer.1.output.LayerNorm.bias\": 768,\n",
            "  \"bert.encoder.layer.2.attention.self.query.weight\": 589824,\n",
            "  \"bert.encoder.layer.2.attention.self.query.bias\": 768,\n",
            "  \"bert.encoder.layer.2.attention.self.key.weight\": 589824,\n",
            "  \"bert.encoder.layer.2.attention.self.key.bias\": 768,\n",
            "  \"bert.encoder.layer.2.attention.self.value.weight\": 589824,\n",
            "  \"bert.encoder.layer.2.attention.self.value.bias\": 768,\n",
            "  \"bert.encoder.layer.2.attention.output.dense.weight\": 589824,\n",
            "  \"bert.encoder.layer.2.attention.output.dense.bias\": 768,\n",
            "  \"bert.encoder.layer.2.attention.output.LayerNorm.weight\": 768,\n",
            "  \"bert.encoder.layer.2.attention.output.LayerNorm.bias\": 768,\n",
            "  \"bert.encoder.layer.2.intermediate.dense.weight\": 2359296,\n",
            "  \"bert.encoder.layer.2.intermediate.dense.bias\": 3072,\n",
            "  \"bert.encoder.layer.2.output.dense.weight\": 2359296,\n",
            "  \"bert.encoder.layer.2.output.dense.bias\": 768,\n",
            "  \"bert.encoder.layer.2.output.LayerNorm.weight\": 768,\n",
            "  \"bert.encoder.layer.2.output.LayerNorm.bias\": 768,\n",
            "  \"bert.encoder.layer.3.attention.self.query.weight\": 589824,\n",
            "  \"bert.encoder.layer.3.attention.self.query.bias\": 768,\n",
            "  \"bert.encoder.layer.3.attention.self.key.weight\": 589824,\n",
            "  \"bert.encoder.layer.3.attention.self.key.bias\": 768,\n",
            "  \"bert.encoder.layer.3.attention.self.value.weight\": 589824,\n",
            "  \"bert.encoder.layer.3.attention.self.value.bias\": 768,\n",
            "  \"bert.encoder.layer.3.attention.output.dense.weight\": 589824,\n",
            "  \"bert.encoder.layer.3.attention.output.dense.bias\": 768,\n",
            "  \"bert.encoder.layer.3.attention.output.LayerNorm.weight\": 768,\n",
            "  \"bert.encoder.layer.3.attention.output.LayerNorm.bias\": 768,\n",
            "  \"bert.encoder.layer.3.intermediate.dense.weight\": 2359296,\n",
            "  \"bert.encoder.layer.3.intermediate.dense.bias\": 3072,\n",
            "  \"bert.encoder.layer.3.output.dense.weight\": 2359296,\n",
            "  \"bert.encoder.layer.3.output.dense.bias\": 768,\n",
            "  \"bert.encoder.layer.3.output.LayerNorm.weight\": 768,\n",
            "  \"bert.encoder.layer.3.output.LayerNorm.bias\": 768,\n",
            "  \"bert.encoder.layer.4.attention.self.query.weight\": 589824,\n",
            "  \"bert.encoder.layer.4.attention.self.query.bias\": 768,\n",
            "  \"bert.encoder.layer.4.attention.self.key.weight\": 589824,\n",
            "  \"bert.encoder.layer.4.attention.self.key.bias\": 768,\n",
            "  \"bert.encoder.layer.4.attention.self.value.weight\": 589824,\n",
            "  \"bert.encoder.layer.4.attention.self.value.bias\": 768,\n",
            "  \"bert.encoder.layer.4.attention.output.dense.weight\": 589824,\n",
            "  \"bert.encoder.layer.4.attention.output.dense.bias\": 768,\n",
            "  \"bert.encoder.layer.4.attention.output.LayerNorm.weight\": 768,\n",
            "  \"bert.encoder.layer.4.attention.output.LayerNorm.bias\": 768,\n",
            "  \"bert.encoder.layer.4.intermediate.dense.weight\": 2359296,\n",
            "  \"bert.encoder.layer.4.intermediate.dense.bias\": 3072,\n",
            "  \"bert.encoder.layer.4.output.dense.weight\": 2359296,\n",
            "  \"bert.encoder.layer.4.output.dense.bias\": 768,\n",
            "  \"bert.encoder.layer.4.output.LayerNorm.weight\": 768,\n",
            "  \"bert.encoder.layer.4.output.LayerNorm.bias\": 768,\n",
            "  \"bert.encoder.layer.5.attention.self.query.weight\": 589824,\n",
            "  \"bert.encoder.layer.5.attention.self.query.bias\": 768,\n",
            "  \"bert.encoder.layer.5.attention.self.key.weight\": 589824,\n",
            "  \"bert.encoder.layer.5.attention.self.key.bias\": 768,\n",
            "  \"bert.encoder.layer.5.attention.self.value.weight\": 589824,\n",
            "  \"bert.encoder.layer.5.attention.self.value.bias\": 768,\n",
            "  \"bert.encoder.layer.5.attention.output.dense.weight\": 589824,\n",
            "  \"bert.encoder.layer.5.attention.output.dense.bias\": 768,\n",
            "  \"bert.encoder.layer.5.attention.output.LayerNorm.weight\": 768,\n",
            "  \"bert.encoder.layer.5.attention.output.LayerNorm.bias\": 768,\n",
            "  \"bert.encoder.layer.5.intermediate.dense.weight\": 2359296,\n",
            "  \"bert.encoder.layer.5.intermediate.dense.bias\": 3072,\n",
            "  \"bert.encoder.layer.5.output.dense.weight\": 2359296,\n",
            "  \"bert.encoder.layer.5.output.dense.bias\": 768,\n",
            "  \"bert.encoder.layer.5.output.LayerNorm.weight\": 768,\n",
            "  \"bert.encoder.layer.5.output.LayerNorm.bias\": 768,\n",
            "  \"bert.encoder.layer.6.attention.self.query.weight\": 589824,\n",
            "  \"bert.encoder.layer.6.attention.self.query.bias\": 768,\n",
            "  \"bert.encoder.layer.6.attention.self.key.weight\": 589824,\n",
            "  \"bert.encoder.layer.6.attention.self.key.bias\": 768,\n",
            "  \"bert.encoder.layer.6.attention.self.value.weight\": 589824,\n",
            "  \"bert.encoder.layer.6.attention.self.value.bias\": 768,\n",
            "  \"bert.encoder.layer.6.attention.output.dense.weight\": 589824,\n",
            "  \"bert.encoder.layer.6.attention.output.dense.bias\": 768,\n",
            "  \"bert.encoder.layer.6.attention.output.LayerNorm.weight\": 768,\n",
            "  \"bert.encoder.layer.6.attention.output.LayerNorm.bias\": 768,\n",
            "  \"bert.encoder.layer.6.intermediate.dense.weight\": 2359296,\n",
            "  \"bert.encoder.layer.6.intermediate.dense.bias\": 3072,\n",
            "  \"bert.encoder.layer.6.output.dense.weight\": 2359296,\n",
            "  \"bert.encoder.layer.6.output.dense.bias\": 768,\n",
            "  \"bert.encoder.layer.6.output.LayerNorm.weight\": 768,\n",
            "  \"bert.encoder.layer.6.output.LayerNorm.bias\": 768,\n",
            "  \"bert.encoder.layer.7.attention.self.query.weight\": 589824,\n",
            "  \"bert.encoder.layer.7.attention.self.query.bias\": 768,\n",
            "  \"bert.encoder.layer.7.attention.self.key.weight\": 589824,\n",
            "  \"bert.encoder.layer.7.attention.self.key.bias\": 768,\n",
            "  \"bert.encoder.layer.7.attention.self.value.weight\": 589824,\n",
            "  \"bert.encoder.layer.7.attention.self.value.bias\": 768,\n",
            "  \"bert.encoder.layer.7.attention.output.dense.weight\": 589824,\n",
            "  \"bert.encoder.layer.7.attention.output.dense.bias\": 768,\n",
            "  \"bert.encoder.layer.7.attention.output.LayerNorm.weight\": 768,\n",
            "  \"bert.encoder.layer.7.attention.output.LayerNorm.bias\": 768,\n",
            "  \"bert.encoder.layer.7.intermediate.dense.weight\": 2359296,\n",
            "  \"bert.encoder.layer.7.intermediate.dense.bias\": 3072,\n",
            "  \"bert.encoder.layer.7.output.dense.weight\": 2359296,\n",
            "  \"bert.encoder.layer.7.output.dense.bias\": 768,\n",
            "  \"bert.encoder.layer.7.output.LayerNorm.weight\": 768,\n",
            "  \"bert.encoder.layer.7.output.LayerNorm.bias\": 768,\n",
            "  \"bert.encoder.layer.8.attention.self.query.weight\": 589824,\n",
            "  \"bert.encoder.layer.8.attention.self.query.bias\": 768,\n",
            "  \"bert.encoder.layer.8.attention.self.key.weight\": 589824,\n",
            "  \"bert.encoder.layer.8.attention.self.key.bias\": 768,\n",
            "  \"bert.encoder.layer.8.attention.self.value.weight\": 589824,\n",
            "  \"bert.encoder.layer.8.attention.self.value.bias\": 768,\n",
            "  \"bert.encoder.layer.8.attention.output.dense.weight\": 589824,\n",
            "  \"bert.encoder.layer.8.attention.output.dense.bias\": 768,\n",
            "  \"bert.encoder.layer.8.attention.output.LayerNorm.weight\": 768,\n",
            "  \"bert.encoder.layer.8.attention.output.LayerNorm.bias\": 768,\n",
            "  \"bert.encoder.layer.8.intermediate.dense.weight\": 2359296,\n",
            "  \"bert.encoder.layer.8.intermediate.dense.bias\": 3072,\n",
            "  \"bert.encoder.layer.8.output.dense.weight\": 2359296,\n",
            "  \"bert.encoder.layer.8.output.dense.bias\": 768,\n",
            "  \"bert.encoder.layer.8.output.LayerNorm.weight\": 768,\n",
            "  \"bert.encoder.layer.8.output.LayerNorm.bias\": 768,\n",
            "  \"bert.encoder.layer.9.attention.self.query.weight\": 589824,\n",
            "  \"bert.encoder.layer.9.attention.self.query.bias\": 768,\n",
            "  \"bert.encoder.layer.9.attention.self.key.weight\": 589824,\n",
            "  \"bert.encoder.layer.9.attention.self.key.bias\": 768,\n",
            "  \"bert.encoder.layer.9.attention.self.value.weight\": 589824,\n",
            "  \"bert.encoder.layer.9.attention.self.value.bias\": 768,\n",
            "  \"bert.encoder.layer.9.attention.output.dense.weight\": 589824,\n",
            "  \"bert.encoder.layer.9.attention.output.dense.bias\": 768,\n",
            "  \"bert.encoder.layer.9.attention.output.LayerNorm.weight\": 768,\n",
            "  \"bert.encoder.layer.9.attention.output.LayerNorm.bias\": 768,\n",
            "  \"bert.encoder.layer.9.intermediate.dense.weight\": 2359296,\n",
            "  \"bert.encoder.layer.9.intermediate.dense.bias\": 3072,\n",
            "  \"bert.encoder.layer.9.output.dense.weight\": 2359296,\n",
            "  \"bert.encoder.layer.9.output.dense.bias\": 768,\n",
            "  \"bert.encoder.layer.9.output.LayerNorm.weight\": 768,\n",
            "  \"bert.encoder.layer.9.output.LayerNorm.bias\": 768,\n",
            "  \"bert.encoder.layer.10.attention.self.query.weight\": 589824,\n",
            "  \"bert.encoder.layer.10.attention.self.query.bias\": 768,\n",
            "  \"bert.encoder.layer.10.attention.self.key.weight\": 589824,\n",
            "  \"bert.encoder.layer.10.attention.self.key.bias\": 768,\n",
            "  \"bert.encoder.layer.10.attention.self.value.weight\": 589824,\n",
            "  \"bert.encoder.layer.10.attention.self.value.bias\": 768,\n",
            "  \"bert.encoder.layer.10.attention.output.dense.weight\": 589824,\n",
            "  \"bert.encoder.layer.10.attention.output.dense.bias\": 768,\n",
            "  \"bert.encoder.layer.10.attention.output.LayerNorm.weight\": 768,\n",
            "  \"bert.encoder.layer.10.attention.output.LayerNorm.bias\": 768,\n",
            "  \"bert.encoder.layer.10.intermediate.dense.weight\": 2359296,\n",
            "  \"bert.encoder.layer.10.intermediate.dense.bias\": 3072,\n",
            "  \"bert.encoder.layer.10.output.dense.weight\": 2359296,\n",
            "  \"bert.encoder.layer.10.output.dense.bias\": 768,\n",
            "  \"bert.encoder.layer.10.output.LayerNorm.weight\": 768,\n",
            "  \"bert.encoder.layer.10.output.LayerNorm.bias\": 768,\n",
            "  \"bert.encoder.layer.11.attention.self.query.weight\": 589824,\n",
            "  \"bert.encoder.layer.11.attention.self.query.bias\": 768,\n",
            "  \"bert.encoder.layer.11.attention.self.key.weight\": 589824,\n",
            "  \"bert.encoder.layer.11.attention.self.key.bias\": 768,\n",
            "  \"bert.encoder.layer.11.attention.self.value.weight\": 589824,\n",
            "  \"bert.encoder.layer.11.attention.self.value.bias\": 768,\n",
            "  \"bert.encoder.layer.11.attention.output.dense.weight\": 589824,\n",
            "  \"bert.encoder.layer.11.attention.output.dense.bias\": 768,\n",
            "  \"bert.encoder.layer.11.attention.output.LayerNorm.weight\": 768,\n",
            "  \"bert.encoder.layer.11.attention.output.LayerNorm.bias\": 768,\n",
            "  \"bert.encoder.layer.11.intermediate.dense.weight\": 2359296,\n",
            "  \"bert.encoder.layer.11.intermediate.dense.bias\": 3072,\n",
            "  \"bert.encoder.layer.11.output.dense.weight\": 2359296,\n",
            "  \"bert.encoder.layer.11.output.dense.bias\": 768,\n",
            "  \"bert.encoder.layer.11.output.LayerNorm.weight\": 768,\n",
            "  \"bert.encoder.layer.11.output.LayerNorm.bias\": 768,\n",
            "  \"feat_map.weight\": 196608,\n",
            "  \"feat_map.bias\": 256,\n",
            "  \"input_proj.0.0.weight\": 49152,\n",
            "  \"input_proj.0.0.bias\": 256,\n",
            "  \"input_proj.0.1.weight\": 256,\n",
            "  \"input_proj.0.1.bias\": 256,\n",
            "  \"input_proj.1.0.weight\": 98304,\n",
            "  \"input_proj.1.0.bias\": 256,\n",
            "  \"input_proj.1.1.weight\": 256,\n",
            "  \"input_proj.1.1.bias\": 256,\n",
            "  \"input_proj.2.0.weight\": 196608,\n",
            "  \"input_proj.2.0.bias\": 256,\n",
            "  \"input_proj.2.1.weight\": 256,\n",
            "  \"input_proj.2.1.bias\": 256,\n",
            "  \"input_proj.3.0.weight\": 1769472,\n",
            "  \"input_proj.3.0.bias\": 256,\n",
            "  \"input_proj.3.1.weight\": 256,\n",
            "  \"input_proj.3.1.bias\": 256,\n",
            "  \"backbone.0.patch_embed.proj.weight\": 4608,\n",
            "  \"backbone.0.patch_embed.proj.bias\": 96,\n",
            "  \"backbone.0.patch_embed.norm.weight\": 96,\n",
            "  \"backbone.0.patch_embed.norm.bias\": 96,\n",
            "  \"backbone.0.layers.0.blocks.0.norm1.weight\": 96,\n",
            "  \"backbone.0.layers.0.blocks.0.norm1.bias\": 96,\n",
            "  \"backbone.0.layers.0.blocks.0.attn.relative_position_bias_table\": 507,\n",
            "  \"backbone.0.layers.0.blocks.0.attn.qkv.weight\": 27648,\n",
            "  \"backbone.0.layers.0.blocks.0.attn.qkv.bias\": 288,\n",
            "  \"backbone.0.layers.0.blocks.0.attn.proj.weight\": 9216,\n",
            "  \"backbone.0.layers.0.blocks.0.attn.proj.bias\": 96,\n",
            "  \"backbone.0.layers.0.blocks.0.norm2.weight\": 96,\n",
            "  \"backbone.0.layers.0.blocks.0.norm2.bias\": 96,\n",
            "  \"backbone.0.layers.0.blocks.0.mlp.fc1.weight\": 36864,\n",
            "  \"backbone.0.layers.0.blocks.0.mlp.fc1.bias\": 384,\n",
            "  \"backbone.0.layers.0.blocks.0.mlp.fc2.weight\": 36864,\n",
            "  \"backbone.0.layers.0.blocks.0.mlp.fc2.bias\": 96,\n",
            "  \"backbone.0.layers.0.blocks.1.norm1.weight\": 96,\n",
            "  \"backbone.0.layers.0.blocks.1.norm1.bias\": 96,\n",
            "  \"backbone.0.layers.0.blocks.1.attn.relative_position_bias_table\": 507,\n",
            "  \"backbone.0.layers.0.blocks.1.attn.qkv.weight\": 27648,\n",
            "  \"backbone.0.layers.0.blocks.1.attn.qkv.bias\": 288,\n",
            "  \"backbone.0.layers.0.blocks.1.attn.proj.weight\": 9216,\n",
            "  \"backbone.0.layers.0.blocks.1.attn.proj.bias\": 96,\n",
            "  \"backbone.0.layers.0.blocks.1.norm2.weight\": 96,\n",
            "  \"backbone.0.layers.0.blocks.1.norm2.bias\": 96,\n",
            "  \"backbone.0.layers.0.blocks.1.mlp.fc1.weight\": 36864,\n",
            "  \"backbone.0.layers.0.blocks.1.mlp.fc1.bias\": 384,\n",
            "  \"backbone.0.layers.0.blocks.1.mlp.fc2.weight\": 36864,\n",
            "  \"backbone.0.layers.0.blocks.1.mlp.fc2.bias\": 96,\n",
            "  \"backbone.0.layers.0.downsample.reduction.weight\": 73728,\n",
            "  \"backbone.0.layers.0.downsample.norm.weight\": 384,\n",
            "  \"backbone.0.layers.0.downsample.norm.bias\": 384,\n",
            "  \"backbone.0.layers.1.blocks.0.norm1.weight\": 192,\n",
            "  \"backbone.0.layers.1.blocks.0.norm1.bias\": 192,\n",
            "  \"backbone.0.layers.1.blocks.0.attn.relative_position_bias_table\": 1014,\n",
            "  \"backbone.0.layers.1.blocks.0.attn.qkv.weight\": 110592,\n",
            "  \"backbone.0.layers.1.blocks.0.attn.qkv.bias\": 576,\n",
            "  \"backbone.0.layers.1.blocks.0.attn.proj.weight\": 36864,\n",
            "  \"backbone.0.layers.1.blocks.0.attn.proj.bias\": 192,\n",
            "  \"backbone.0.layers.1.blocks.0.norm2.weight\": 192,\n",
            "  \"backbone.0.layers.1.blocks.0.norm2.bias\": 192,\n",
            "  \"backbone.0.layers.1.blocks.0.mlp.fc1.weight\": 147456,\n",
            "  \"backbone.0.layers.1.blocks.0.mlp.fc1.bias\": 768,\n",
            "  \"backbone.0.layers.1.blocks.0.mlp.fc2.weight\": 147456,\n",
            "  \"backbone.0.layers.1.blocks.0.mlp.fc2.bias\": 192,\n",
            "  \"backbone.0.layers.1.blocks.1.norm1.weight\": 192,\n",
            "  \"backbone.0.layers.1.blocks.1.norm1.bias\": 192,\n",
            "  \"backbone.0.layers.1.blocks.1.attn.relative_position_bias_table\": 1014,\n",
            "  \"backbone.0.layers.1.blocks.1.attn.qkv.weight\": 110592,\n",
            "  \"backbone.0.layers.1.blocks.1.attn.qkv.bias\": 576,\n",
            "  \"backbone.0.layers.1.blocks.1.attn.proj.weight\": 36864,\n",
            "  \"backbone.0.layers.1.blocks.1.attn.proj.bias\": 192,\n",
            "  \"backbone.0.layers.1.blocks.1.norm2.weight\": 192,\n",
            "  \"backbone.0.layers.1.blocks.1.norm2.bias\": 192,\n",
            "  \"backbone.0.layers.1.blocks.1.mlp.fc1.weight\": 147456,\n",
            "  \"backbone.0.layers.1.blocks.1.mlp.fc1.bias\": 768,\n",
            "  \"backbone.0.layers.1.blocks.1.mlp.fc2.weight\": 147456,\n",
            "  \"backbone.0.layers.1.blocks.1.mlp.fc2.bias\": 192,\n",
            "  \"backbone.0.layers.1.downsample.reduction.weight\": 294912,\n",
            "  \"backbone.0.layers.1.downsample.norm.weight\": 768,\n",
            "  \"backbone.0.layers.1.downsample.norm.bias\": 768,\n",
            "  \"backbone.0.layers.2.blocks.0.norm1.weight\": 384,\n",
            "  \"backbone.0.layers.2.blocks.0.norm1.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.0.attn.relative_position_bias_table\": 2028,\n",
            "  \"backbone.0.layers.2.blocks.0.attn.qkv.weight\": 442368,\n",
            "  \"backbone.0.layers.2.blocks.0.attn.qkv.bias\": 1152,\n",
            "  \"backbone.0.layers.2.blocks.0.attn.proj.weight\": 147456,\n",
            "  \"backbone.0.layers.2.blocks.0.attn.proj.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.0.norm2.weight\": 384,\n",
            "  \"backbone.0.layers.2.blocks.0.norm2.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.0.mlp.fc1.weight\": 589824,\n",
            "  \"backbone.0.layers.2.blocks.0.mlp.fc1.bias\": 1536,\n",
            "  \"backbone.0.layers.2.blocks.0.mlp.fc2.weight\": 589824,\n",
            "  \"backbone.0.layers.2.blocks.0.mlp.fc2.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.1.norm1.weight\": 384,\n",
            "  \"backbone.0.layers.2.blocks.1.norm1.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.1.attn.relative_position_bias_table\": 2028,\n",
            "  \"backbone.0.layers.2.blocks.1.attn.qkv.weight\": 442368,\n",
            "  \"backbone.0.layers.2.blocks.1.attn.qkv.bias\": 1152,\n",
            "  \"backbone.0.layers.2.blocks.1.attn.proj.weight\": 147456,\n",
            "  \"backbone.0.layers.2.blocks.1.attn.proj.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.1.norm2.weight\": 384,\n",
            "  \"backbone.0.layers.2.blocks.1.norm2.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.1.mlp.fc1.weight\": 589824,\n",
            "  \"backbone.0.layers.2.blocks.1.mlp.fc1.bias\": 1536,\n",
            "  \"backbone.0.layers.2.blocks.1.mlp.fc2.weight\": 589824,\n",
            "  \"backbone.0.layers.2.blocks.1.mlp.fc2.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.2.norm1.weight\": 384,\n",
            "  \"backbone.0.layers.2.blocks.2.norm1.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.2.attn.relative_position_bias_table\": 2028,\n",
            "  \"backbone.0.layers.2.blocks.2.attn.qkv.weight\": 442368,\n",
            "  \"backbone.0.layers.2.blocks.2.attn.qkv.bias\": 1152,\n",
            "  \"backbone.0.layers.2.blocks.2.attn.proj.weight\": 147456,\n",
            "  \"backbone.0.layers.2.blocks.2.attn.proj.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.2.norm2.weight\": 384,\n",
            "  \"backbone.0.layers.2.blocks.2.norm2.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.2.mlp.fc1.weight\": 589824,\n",
            "  \"backbone.0.layers.2.blocks.2.mlp.fc1.bias\": 1536,\n",
            "  \"backbone.0.layers.2.blocks.2.mlp.fc2.weight\": 589824,\n",
            "  \"backbone.0.layers.2.blocks.2.mlp.fc2.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.3.norm1.weight\": 384,\n",
            "  \"backbone.0.layers.2.blocks.3.norm1.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.3.attn.relative_position_bias_table\": 2028,\n",
            "  \"backbone.0.layers.2.blocks.3.attn.qkv.weight\": 442368,\n",
            "  \"backbone.0.layers.2.blocks.3.attn.qkv.bias\": 1152,\n",
            "  \"backbone.0.layers.2.blocks.3.attn.proj.weight\": 147456,\n",
            "  \"backbone.0.layers.2.blocks.3.attn.proj.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.3.norm2.weight\": 384,\n",
            "  \"backbone.0.layers.2.blocks.3.norm2.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.3.mlp.fc1.weight\": 589824,\n",
            "  \"backbone.0.layers.2.blocks.3.mlp.fc1.bias\": 1536,\n",
            "  \"backbone.0.layers.2.blocks.3.mlp.fc2.weight\": 589824,\n",
            "  \"backbone.0.layers.2.blocks.3.mlp.fc2.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.4.norm1.weight\": 384,\n",
            "  \"backbone.0.layers.2.blocks.4.norm1.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.4.attn.relative_position_bias_table\": 2028,\n",
            "  \"backbone.0.layers.2.blocks.4.attn.qkv.weight\": 442368,\n",
            "  \"backbone.0.layers.2.blocks.4.attn.qkv.bias\": 1152,\n",
            "  \"backbone.0.layers.2.blocks.4.attn.proj.weight\": 147456,\n",
            "  \"backbone.0.layers.2.blocks.4.attn.proj.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.4.norm2.weight\": 384,\n",
            "  \"backbone.0.layers.2.blocks.4.norm2.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.4.mlp.fc1.weight\": 589824,\n",
            "  \"backbone.0.layers.2.blocks.4.mlp.fc1.bias\": 1536,\n",
            "  \"backbone.0.layers.2.blocks.4.mlp.fc2.weight\": 589824,\n",
            "  \"backbone.0.layers.2.blocks.4.mlp.fc2.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.5.norm1.weight\": 384,\n",
            "  \"backbone.0.layers.2.blocks.5.norm1.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.5.attn.relative_position_bias_table\": 2028,\n",
            "  \"backbone.0.layers.2.blocks.5.attn.qkv.weight\": 442368,\n",
            "  \"backbone.0.layers.2.blocks.5.attn.qkv.bias\": 1152,\n",
            "  \"backbone.0.layers.2.blocks.5.attn.proj.weight\": 147456,\n",
            "  \"backbone.0.layers.2.blocks.5.attn.proj.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.5.norm2.weight\": 384,\n",
            "  \"backbone.0.layers.2.blocks.5.norm2.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.5.mlp.fc1.weight\": 589824,\n",
            "  \"backbone.0.layers.2.blocks.5.mlp.fc1.bias\": 1536,\n",
            "  \"backbone.0.layers.2.blocks.5.mlp.fc2.weight\": 589824,\n",
            "  \"backbone.0.layers.2.blocks.5.mlp.fc2.bias\": 384,\n",
            "  \"backbone.0.layers.2.downsample.reduction.weight\": 1179648,\n",
            "  \"backbone.0.layers.2.downsample.norm.weight\": 1536,\n",
            "  \"backbone.0.layers.2.downsample.norm.bias\": 1536,\n",
            "  \"backbone.0.layers.3.blocks.0.norm1.weight\": 768,\n",
            "  \"backbone.0.layers.3.blocks.0.norm1.bias\": 768,\n",
            "  \"backbone.0.layers.3.blocks.0.attn.relative_position_bias_table\": 4056,\n",
            "  \"backbone.0.layers.3.blocks.0.attn.qkv.weight\": 1769472,\n",
            "  \"backbone.0.layers.3.blocks.0.attn.qkv.bias\": 2304,\n",
            "  \"backbone.0.layers.3.blocks.0.attn.proj.weight\": 589824,\n",
            "  \"backbone.0.layers.3.blocks.0.attn.proj.bias\": 768,\n",
            "  \"backbone.0.layers.3.blocks.0.norm2.weight\": 768,\n",
            "  \"backbone.0.layers.3.blocks.0.norm2.bias\": 768,\n",
            "  \"backbone.0.layers.3.blocks.0.mlp.fc1.weight\": 2359296,\n",
            "  \"backbone.0.layers.3.blocks.0.mlp.fc1.bias\": 3072,\n",
            "  \"backbone.0.layers.3.blocks.0.mlp.fc2.weight\": 2359296,\n",
            "  \"backbone.0.layers.3.blocks.0.mlp.fc2.bias\": 768,\n",
            "  \"backbone.0.layers.3.blocks.1.norm1.weight\": 768,\n",
            "  \"backbone.0.layers.3.blocks.1.norm1.bias\": 768,\n",
            "  \"backbone.0.layers.3.blocks.1.attn.relative_position_bias_table\": 4056,\n",
            "  \"backbone.0.layers.3.blocks.1.attn.qkv.weight\": 1769472,\n",
            "  \"backbone.0.layers.3.blocks.1.attn.qkv.bias\": 2304,\n",
            "  \"backbone.0.layers.3.blocks.1.attn.proj.weight\": 589824,\n",
            "  \"backbone.0.layers.3.blocks.1.attn.proj.bias\": 768,\n",
            "  \"backbone.0.layers.3.blocks.1.norm2.weight\": 768,\n",
            "  \"backbone.0.layers.3.blocks.1.norm2.bias\": 768,\n",
            "  \"backbone.0.layers.3.blocks.1.mlp.fc1.weight\": 2359296,\n",
            "  \"backbone.0.layers.3.blocks.1.mlp.fc1.bias\": 3072,\n",
            "  \"backbone.0.layers.3.blocks.1.mlp.fc2.weight\": 2359296,\n",
            "  \"backbone.0.layers.3.blocks.1.mlp.fc2.bias\": 768,\n",
            "  \"backbone.0.norm1.weight\": 192,\n",
            "  \"backbone.0.norm1.bias\": 192,\n",
            "  \"backbone.0.norm2.weight\": 384,\n",
            "  \"backbone.0.norm2.bias\": 384,\n",
            "  \"backbone.0.norm3.weight\": 768,\n",
            "  \"backbone.0.norm3.bias\": 768\n",
            "}\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[32m2023-12-14 08:07:53,455 | \u001b[34mparams after freezing:\n",
            "{\n",
            "  \"transformer.level_embed\": 1024,\n",
            "  \"transformer.encoder.layers.0.self_attn.sampling_offsets.weight\": 65536,\n",
            "  \"transformer.encoder.layers.0.self_attn.sampling_offsets.bias\": 256,\n",
            "  \"transformer.encoder.layers.0.self_attn.attention_weights.weight\": 32768,\n",
            "  \"transformer.encoder.layers.0.self_attn.attention_weights.bias\": 128,\n",
            "  \"transformer.encoder.layers.0.self_attn.value_proj.weight\": 65536,\n",
            "  \"transformer.encoder.layers.0.self_attn.value_proj.bias\": 256,\n",
            "  \"transformer.encoder.layers.0.self_attn.output_proj.weight\": 65536,\n",
            "  \"transformer.encoder.layers.0.self_attn.output_proj.bias\": 256,\n",
            "  \"transformer.encoder.layers.0.norm1.weight\": 256,\n",
            "  \"transformer.encoder.layers.0.norm1.bias\": 256,\n",
            "  \"transformer.encoder.layers.0.linear1.weight\": 524288,\n",
            "  \"transformer.encoder.layers.0.linear1.bias\": 2048,\n",
            "  \"transformer.encoder.layers.0.linear2.weight\": 524288,\n",
            "  \"transformer.encoder.layers.0.linear2.bias\": 256,\n",
            "  \"transformer.encoder.layers.0.norm2.weight\": 256,\n",
            "  \"transformer.encoder.layers.0.norm2.bias\": 256,\n",
            "  \"transformer.encoder.layers.1.self_attn.sampling_offsets.weight\": 65536,\n",
            "  \"transformer.encoder.layers.1.self_attn.sampling_offsets.bias\": 256,\n",
            "  \"transformer.encoder.layers.1.self_attn.attention_weights.weight\": 32768,\n",
            "  \"transformer.encoder.layers.1.self_attn.attention_weights.bias\": 128,\n",
            "  \"transformer.encoder.layers.1.self_attn.value_proj.weight\": 65536,\n",
            "  \"transformer.encoder.layers.1.self_attn.value_proj.bias\": 256,\n",
            "  \"transformer.encoder.layers.1.self_attn.output_proj.weight\": 65536,\n",
            "  \"transformer.encoder.layers.1.self_attn.output_proj.bias\": 256,\n",
            "  \"transformer.encoder.layers.1.norm1.weight\": 256,\n",
            "  \"transformer.encoder.layers.1.norm1.bias\": 256,\n",
            "  \"transformer.encoder.layers.1.linear1.weight\": 524288,\n",
            "  \"transformer.encoder.layers.1.linear1.bias\": 2048,\n",
            "  \"transformer.encoder.layers.1.linear2.weight\": 524288,\n",
            "  \"transformer.encoder.layers.1.linear2.bias\": 256,\n",
            "  \"transformer.encoder.layers.1.norm2.weight\": 256,\n",
            "  \"transformer.encoder.layers.1.norm2.bias\": 256,\n",
            "  \"transformer.encoder.layers.2.self_attn.sampling_offsets.weight\": 65536,\n",
            "  \"transformer.encoder.layers.2.self_attn.sampling_offsets.bias\": 256,\n",
            "  \"transformer.encoder.layers.2.self_attn.attention_weights.weight\": 32768,\n",
            "  \"transformer.encoder.layers.2.self_attn.attention_weights.bias\": 128,\n",
            "  \"transformer.encoder.layers.2.self_attn.value_proj.weight\": 65536,\n",
            "  \"transformer.encoder.layers.2.self_attn.value_proj.bias\": 256,\n",
            "  \"transformer.encoder.layers.2.self_attn.output_proj.weight\": 65536,\n",
            "  \"transformer.encoder.layers.2.self_attn.output_proj.bias\": 256,\n",
            "  \"transformer.encoder.layers.2.norm1.weight\": 256,\n",
            "  \"transformer.encoder.layers.2.norm1.bias\": 256,\n",
            "  \"transformer.encoder.layers.2.linear1.weight\": 524288,\n",
            "  \"transformer.encoder.layers.2.linear1.bias\": 2048,\n",
            "  \"transformer.encoder.layers.2.linear2.weight\": 524288,\n",
            "  \"transformer.encoder.layers.2.linear2.bias\": 256,\n",
            "  \"transformer.encoder.layers.2.norm2.weight\": 256,\n",
            "  \"transformer.encoder.layers.2.norm2.bias\": 256,\n",
            "  \"transformer.encoder.layers.3.self_attn.sampling_offsets.weight\": 65536,\n",
            "  \"transformer.encoder.layers.3.self_attn.sampling_offsets.bias\": 256,\n",
            "  \"transformer.encoder.layers.3.self_attn.attention_weights.weight\": 32768,\n",
            "  \"transformer.encoder.layers.3.self_attn.attention_weights.bias\": 128,\n",
            "  \"transformer.encoder.layers.3.self_attn.value_proj.weight\": 65536,\n",
            "  \"transformer.encoder.layers.3.self_attn.value_proj.bias\": 256,\n",
            "  \"transformer.encoder.layers.3.self_attn.output_proj.weight\": 65536,\n",
            "  \"transformer.encoder.layers.3.self_attn.output_proj.bias\": 256,\n",
            "  \"transformer.encoder.layers.3.norm1.weight\": 256,\n",
            "  \"transformer.encoder.layers.3.norm1.bias\": 256,\n",
            "  \"transformer.encoder.layers.3.linear1.weight\": 524288,\n",
            "  \"transformer.encoder.layers.3.linear1.bias\": 2048,\n",
            "  \"transformer.encoder.layers.3.linear2.weight\": 524288,\n",
            "  \"transformer.encoder.layers.3.linear2.bias\": 256,\n",
            "  \"transformer.encoder.layers.3.norm2.weight\": 256,\n",
            "  \"transformer.encoder.layers.3.norm2.bias\": 256,\n",
            "  \"transformer.encoder.layers.4.self_attn.sampling_offsets.weight\": 65536,\n",
            "  \"transformer.encoder.layers.4.self_attn.sampling_offsets.bias\": 256,\n",
            "  \"transformer.encoder.layers.4.self_attn.attention_weights.weight\": 32768,\n",
            "  \"transformer.encoder.layers.4.self_attn.attention_weights.bias\": 128,\n",
            "  \"transformer.encoder.layers.4.self_attn.value_proj.weight\": 65536,\n",
            "  \"transformer.encoder.layers.4.self_attn.value_proj.bias\": 256,\n",
            "  \"transformer.encoder.layers.4.self_attn.output_proj.weight\": 65536,\n",
            "  \"transformer.encoder.layers.4.self_attn.output_proj.bias\": 256,\n",
            "  \"transformer.encoder.layers.4.norm1.weight\": 256,\n",
            "  \"transformer.encoder.layers.4.norm1.bias\": 256,\n",
            "  \"transformer.encoder.layers.4.linear1.weight\": 524288,\n",
            "  \"transformer.encoder.layers.4.linear1.bias\": 2048,\n",
            "  \"transformer.encoder.layers.4.linear2.weight\": 524288,\n",
            "  \"transformer.encoder.layers.4.linear2.bias\": 256,\n",
            "  \"transformer.encoder.layers.4.norm2.weight\": 256,\n",
            "  \"transformer.encoder.layers.4.norm2.bias\": 256,\n",
            "  \"transformer.encoder.layers.5.self_attn.sampling_offsets.weight\": 65536,\n",
            "  \"transformer.encoder.layers.5.self_attn.sampling_offsets.bias\": 256,\n",
            "  \"transformer.encoder.layers.5.self_attn.attention_weights.weight\": 32768,\n",
            "  \"transformer.encoder.layers.5.self_attn.attention_weights.bias\": 128,\n",
            "  \"transformer.encoder.layers.5.self_attn.value_proj.weight\": 65536,\n",
            "  \"transformer.encoder.layers.5.self_attn.value_proj.bias\": 256,\n",
            "  \"transformer.encoder.layers.5.self_attn.output_proj.weight\": 65536,\n",
            "  \"transformer.encoder.layers.5.self_attn.output_proj.bias\": 256,\n",
            "  \"transformer.encoder.layers.5.norm1.weight\": 256,\n",
            "  \"transformer.encoder.layers.5.norm1.bias\": 256,\n",
            "  \"transformer.encoder.layers.5.linear1.weight\": 524288,\n",
            "  \"transformer.encoder.layers.5.linear1.bias\": 2048,\n",
            "  \"transformer.encoder.layers.5.linear2.weight\": 524288,\n",
            "  \"transformer.encoder.layers.5.linear2.bias\": 256,\n",
            "  \"transformer.encoder.layers.5.norm2.weight\": 256,\n",
            "  \"transformer.encoder.layers.5.norm2.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.0.self_attn.in_proj_weight\": 196608,\n",
            "  \"transformer.encoder.text_layers.0.self_attn.in_proj_bias\": 768,\n",
            "  \"transformer.encoder.text_layers.0.self_attn.out_proj.weight\": 65536,\n",
            "  \"transformer.encoder.text_layers.0.self_attn.out_proj.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.0.linear1.weight\": 262144,\n",
            "  \"transformer.encoder.text_layers.0.linear1.bias\": 1024,\n",
            "  \"transformer.encoder.text_layers.0.linear2.weight\": 262144,\n",
            "  \"transformer.encoder.text_layers.0.linear2.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.0.norm1.weight\": 256,\n",
            "  \"transformer.encoder.text_layers.0.norm1.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.0.norm2.weight\": 256,\n",
            "  \"transformer.encoder.text_layers.0.norm2.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.1.self_attn.in_proj_weight\": 196608,\n",
            "  \"transformer.encoder.text_layers.1.self_attn.in_proj_bias\": 768,\n",
            "  \"transformer.encoder.text_layers.1.self_attn.out_proj.weight\": 65536,\n",
            "  \"transformer.encoder.text_layers.1.self_attn.out_proj.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.1.linear1.weight\": 262144,\n",
            "  \"transformer.encoder.text_layers.1.linear1.bias\": 1024,\n",
            "  \"transformer.encoder.text_layers.1.linear2.weight\": 262144,\n",
            "  \"transformer.encoder.text_layers.1.linear2.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.1.norm1.weight\": 256,\n",
            "  \"transformer.encoder.text_layers.1.norm1.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.1.norm2.weight\": 256,\n",
            "  \"transformer.encoder.text_layers.1.norm2.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.2.self_attn.in_proj_weight\": 196608,\n",
            "  \"transformer.encoder.text_layers.2.self_attn.in_proj_bias\": 768,\n",
            "  \"transformer.encoder.text_layers.2.self_attn.out_proj.weight\": 65536,\n",
            "  \"transformer.encoder.text_layers.2.self_attn.out_proj.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.2.linear1.weight\": 262144,\n",
            "  \"transformer.encoder.text_layers.2.linear1.bias\": 1024,\n",
            "  \"transformer.encoder.text_layers.2.linear2.weight\": 262144,\n",
            "  \"transformer.encoder.text_layers.2.linear2.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.2.norm1.weight\": 256,\n",
            "  \"transformer.encoder.text_layers.2.norm1.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.2.norm2.weight\": 256,\n",
            "  \"transformer.encoder.text_layers.2.norm2.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.3.self_attn.in_proj_weight\": 196608,\n",
            "  \"transformer.encoder.text_layers.3.self_attn.in_proj_bias\": 768,\n",
            "  \"transformer.encoder.text_layers.3.self_attn.out_proj.weight\": 65536,\n",
            "  \"transformer.encoder.text_layers.3.self_attn.out_proj.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.3.linear1.weight\": 262144,\n",
            "  \"transformer.encoder.text_layers.3.linear1.bias\": 1024,\n",
            "  \"transformer.encoder.text_layers.3.linear2.weight\": 262144,\n",
            "  \"transformer.encoder.text_layers.3.linear2.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.3.norm1.weight\": 256,\n",
            "  \"transformer.encoder.text_layers.3.norm1.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.3.norm2.weight\": 256,\n",
            "  \"transformer.encoder.text_layers.3.norm2.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.4.self_attn.in_proj_weight\": 196608,\n",
            "  \"transformer.encoder.text_layers.4.self_attn.in_proj_bias\": 768,\n",
            "  \"transformer.encoder.text_layers.4.self_attn.out_proj.weight\": 65536,\n",
            "  \"transformer.encoder.text_layers.4.self_attn.out_proj.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.4.linear1.weight\": 262144,\n",
            "  \"transformer.encoder.text_layers.4.linear1.bias\": 1024,\n",
            "  \"transformer.encoder.text_layers.4.linear2.weight\": 262144,\n",
            "  \"transformer.encoder.text_layers.4.linear2.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.4.norm1.weight\": 256,\n",
            "  \"transformer.encoder.text_layers.4.norm1.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.4.norm2.weight\": 256,\n",
            "  \"transformer.encoder.text_layers.4.norm2.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.5.self_attn.in_proj_weight\": 196608,\n",
            "  \"transformer.encoder.text_layers.5.self_attn.in_proj_bias\": 768,\n",
            "  \"transformer.encoder.text_layers.5.self_attn.out_proj.weight\": 65536,\n",
            "  \"transformer.encoder.text_layers.5.self_attn.out_proj.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.5.linear1.weight\": 262144,\n",
            "  \"transformer.encoder.text_layers.5.linear1.bias\": 1024,\n",
            "  \"transformer.encoder.text_layers.5.linear2.weight\": 262144,\n",
            "  \"transformer.encoder.text_layers.5.linear2.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.5.norm1.weight\": 256,\n",
            "  \"transformer.encoder.text_layers.5.norm1.bias\": 256,\n",
            "  \"transformer.encoder.text_layers.5.norm2.weight\": 256,\n",
            "  \"transformer.encoder.text_layers.5.norm2.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.0.gamma_v\": 256,\n",
            "  \"transformer.encoder.fusion_layers.0.gamma_l\": 256,\n",
            "  \"transformer.encoder.fusion_layers.0.layer_norm_v.weight\": 256,\n",
            "  \"transformer.encoder.fusion_layers.0.layer_norm_v.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.0.layer_norm_l.weight\": 256,\n",
            "  \"transformer.encoder.fusion_layers.0.layer_norm_l.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.0.attn.v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.0.attn.v_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.0.attn.l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.0.attn.l_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.0.attn.values_v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.0.attn.values_v_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.0.attn.values_l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.0.attn.values_l_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.0.attn.out_v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.0.attn.out_v_proj.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.0.attn.out_l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.0.attn.out_l_proj.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.1.gamma_v\": 256,\n",
            "  \"transformer.encoder.fusion_layers.1.gamma_l\": 256,\n",
            "  \"transformer.encoder.fusion_layers.1.layer_norm_v.weight\": 256,\n",
            "  \"transformer.encoder.fusion_layers.1.layer_norm_v.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.1.layer_norm_l.weight\": 256,\n",
            "  \"transformer.encoder.fusion_layers.1.layer_norm_l.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.1.attn.v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.1.attn.v_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.1.attn.l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.1.attn.l_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.1.attn.values_v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.1.attn.values_v_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.1.attn.values_l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.1.attn.values_l_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.1.attn.out_v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.1.attn.out_v_proj.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.1.attn.out_l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.1.attn.out_l_proj.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.2.gamma_v\": 256,\n",
            "  \"transformer.encoder.fusion_layers.2.gamma_l\": 256,\n",
            "  \"transformer.encoder.fusion_layers.2.layer_norm_v.weight\": 256,\n",
            "  \"transformer.encoder.fusion_layers.2.layer_norm_v.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.2.layer_norm_l.weight\": 256,\n",
            "  \"transformer.encoder.fusion_layers.2.layer_norm_l.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.2.attn.v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.2.attn.v_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.2.attn.l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.2.attn.l_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.2.attn.values_v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.2.attn.values_v_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.2.attn.values_l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.2.attn.values_l_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.2.attn.out_v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.2.attn.out_v_proj.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.2.attn.out_l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.2.attn.out_l_proj.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.3.gamma_v\": 256,\n",
            "  \"transformer.encoder.fusion_layers.3.gamma_l\": 256,\n",
            "  \"transformer.encoder.fusion_layers.3.layer_norm_v.weight\": 256,\n",
            "  \"transformer.encoder.fusion_layers.3.layer_norm_v.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.3.layer_norm_l.weight\": 256,\n",
            "  \"transformer.encoder.fusion_layers.3.layer_norm_l.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.3.attn.v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.3.attn.v_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.3.attn.l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.3.attn.l_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.3.attn.values_v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.3.attn.values_v_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.3.attn.values_l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.3.attn.values_l_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.3.attn.out_v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.3.attn.out_v_proj.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.3.attn.out_l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.3.attn.out_l_proj.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.4.gamma_v\": 256,\n",
            "  \"transformer.encoder.fusion_layers.4.gamma_l\": 256,\n",
            "  \"transformer.encoder.fusion_layers.4.layer_norm_v.weight\": 256,\n",
            "  \"transformer.encoder.fusion_layers.4.layer_norm_v.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.4.layer_norm_l.weight\": 256,\n",
            "  \"transformer.encoder.fusion_layers.4.layer_norm_l.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.4.attn.v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.4.attn.v_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.4.attn.l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.4.attn.l_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.4.attn.values_v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.4.attn.values_v_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.4.attn.values_l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.4.attn.values_l_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.4.attn.out_v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.4.attn.out_v_proj.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.4.attn.out_l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.4.attn.out_l_proj.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.5.gamma_v\": 256,\n",
            "  \"transformer.encoder.fusion_layers.5.gamma_l\": 256,\n",
            "  \"transformer.encoder.fusion_layers.5.layer_norm_v.weight\": 256,\n",
            "  \"transformer.encoder.fusion_layers.5.layer_norm_v.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.5.layer_norm_l.weight\": 256,\n",
            "  \"transformer.encoder.fusion_layers.5.layer_norm_l.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.5.attn.v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.5.attn.v_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.5.attn.l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.5.attn.l_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.5.attn.values_v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.5.attn.values_v_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.5.attn.values_l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.5.attn.values_l_proj.bias\": 1024,\n",
            "  \"transformer.encoder.fusion_layers.5.attn.out_v_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.5.attn.out_v_proj.bias\": 256,\n",
            "  \"transformer.encoder.fusion_layers.5.attn.out_l_proj.weight\": 262144,\n",
            "  \"transformer.encoder.fusion_layers.5.attn.out_l_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.0.cross_attn.sampling_offsets.weight\": 65536,\n",
            "  \"transformer.decoder.layers.0.cross_attn.sampling_offsets.bias\": 256,\n",
            "  \"transformer.decoder.layers.0.cross_attn.attention_weights.weight\": 32768,\n",
            "  \"transformer.decoder.layers.0.cross_attn.attention_weights.bias\": 128,\n",
            "  \"transformer.decoder.layers.0.cross_attn.value_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.0.cross_attn.value_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.0.cross_attn.output_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.0.cross_attn.output_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.0.norm1.weight\": 256,\n",
            "  \"transformer.decoder.layers.0.norm1.bias\": 256,\n",
            "  \"transformer.decoder.layers.0.ca_text.in_proj_weight\": 196608,\n",
            "  \"transformer.decoder.layers.0.ca_text.in_proj_bias\": 768,\n",
            "  \"transformer.decoder.layers.0.ca_text.out_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.0.ca_text.out_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.0.catext_norm.weight\": 256,\n",
            "  \"transformer.decoder.layers.0.catext_norm.bias\": 256,\n",
            "  \"transformer.decoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
            "  \"transformer.decoder.layers.0.self_attn.in_proj_bias\": 768,\n",
            "  \"transformer.decoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.0.self_attn.out_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.0.norm2.weight\": 256,\n",
            "  \"transformer.decoder.layers.0.norm2.bias\": 256,\n",
            "  \"transformer.decoder.layers.0.linear1.weight\": 524288,\n",
            "  \"transformer.decoder.layers.0.linear1.bias\": 2048,\n",
            "  \"transformer.decoder.layers.0.linear2.weight\": 524288,\n",
            "  \"transformer.decoder.layers.0.linear2.bias\": 256,\n",
            "  \"transformer.decoder.layers.0.norm3.weight\": 256,\n",
            "  \"transformer.decoder.layers.0.norm3.bias\": 256,\n",
            "  \"transformer.decoder.layers.1.cross_attn.sampling_offsets.weight\": 65536,\n",
            "  \"transformer.decoder.layers.1.cross_attn.sampling_offsets.bias\": 256,\n",
            "  \"transformer.decoder.layers.1.cross_attn.attention_weights.weight\": 32768,\n",
            "  \"transformer.decoder.layers.1.cross_attn.attention_weights.bias\": 128,\n",
            "  \"transformer.decoder.layers.1.cross_attn.value_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.1.cross_attn.value_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.1.cross_attn.output_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.1.cross_attn.output_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.1.norm1.weight\": 256,\n",
            "  \"transformer.decoder.layers.1.norm1.bias\": 256,\n",
            "  \"transformer.decoder.layers.1.ca_text.in_proj_weight\": 196608,\n",
            "  \"transformer.decoder.layers.1.ca_text.in_proj_bias\": 768,\n",
            "  \"transformer.decoder.layers.1.ca_text.out_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.1.ca_text.out_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.1.catext_norm.weight\": 256,\n",
            "  \"transformer.decoder.layers.1.catext_norm.bias\": 256,\n",
            "  \"transformer.decoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
            "  \"transformer.decoder.layers.1.self_attn.in_proj_bias\": 768,\n",
            "  \"transformer.decoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.1.self_attn.out_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.1.norm2.weight\": 256,\n",
            "  \"transformer.decoder.layers.1.norm2.bias\": 256,\n",
            "  \"transformer.decoder.layers.1.linear1.weight\": 524288,\n",
            "  \"transformer.decoder.layers.1.linear1.bias\": 2048,\n",
            "  \"transformer.decoder.layers.1.linear2.weight\": 524288,\n",
            "  \"transformer.decoder.layers.1.linear2.bias\": 256,\n",
            "  \"transformer.decoder.layers.1.norm3.weight\": 256,\n",
            "  \"transformer.decoder.layers.1.norm3.bias\": 256,\n",
            "  \"transformer.decoder.layers.2.cross_attn.sampling_offsets.weight\": 65536,\n",
            "  \"transformer.decoder.layers.2.cross_attn.sampling_offsets.bias\": 256,\n",
            "  \"transformer.decoder.layers.2.cross_attn.attention_weights.weight\": 32768,\n",
            "  \"transformer.decoder.layers.2.cross_attn.attention_weights.bias\": 128,\n",
            "  \"transformer.decoder.layers.2.cross_attn.value_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.2.cross_attn.value_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.2.cross_attn.output_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.2.cross_attn.output_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.2.norm1.weight\": 256,\n",
            "  \"transformer.decoder.layers.2.norm1.bias\": 256,\n",
            "  \"transformer.decoder.layers.2.ca_text.in_proj_weight\": 196608,\n",
            "  \"transformer.decoder.layers.2.ca_text.in_proj_bias\": 768,\n",
            "  \"transformer.decoder.layers.2.ca_text.out_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.2.ca_text.out_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.2.catext_norm.weight\": 256,\n",
            "  \"transformer.decoder.layers.2.catext_norm.bias\": 256,\n",
            "  \"transformer.decoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
            "  \"transformer.decoder.layers.2.self_attn.in_proj_bias\": 768,\n",
            "  \"transformer.decoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.2.self_attn.out_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.2.norm2.weight\": 256,\n",
            "  \"transformer.decoder.layers.2.norm2.bias\": 256,\n",
            "  \"transformer.decoder.layers.2.linear1.weight\": 524288,\n",
            "  \"transformer.decoder.layers.2.linear1.bias\": 2048,\n",
            "  \"transformer.decoder.layers.2.linear2.weight\": 524288,\n",
            "  \"transformer.decoder.layers.2.linear2.bias\": 256,\n",
            "  \"transformer.decoder.layers.2.norm3.weight\": 256,\n",
            "  \"transformer.decoder.layers.2.norm3.bias\": 256,\n",
            "  \"transformer.decoder.layers.3.cross_attn.sampling_offsets.weight\": 65536,\n",
            "  \"transformer.decoder.layers.3.cross_attn.sampling_offsets.bias\": 256,\n",
            "  \"transformer.decoder.layers.3.cross_attn.attention_weights.weight\": 32768,\n",
            "  \"transformer.decoder.layers.3.cross_attn.attention_weights.bias\": 128,\n",
            "  \"transformer.decoder.layers.3.cross_attn.value_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.3.cross_attn.value_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.3.cross_attn.output_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.3.cross_attn.output_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.3.norm1.weight\": 256,\n",
            "  \"transformer.decoder.layers.3.norm1.bias\": 256,\n",
            "  \"transformer.decoder.layers.3.ca_text.in_proj_weight\": 196608,\n",
            "  \"transformer.decoder.layers.3.ca_text.in_proj_bias\": 768,\n",
            "  \"transformer.decoder.layers.3.ca_text.out_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.3.ca_text.out_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.3.catext_norm.weight\": 256,\n",
            "  \"transformer.decoder.layers.3.catext_norm.bias\": 256,\n",
            "  \"transformer.decoder.layers.3.self_attn.in_proj_weight\": 196608,\n",
            "  \"transformer.decoder.layers.3.self_attn.in_proj_bias\": 768,\n",
            "  \"transformer.decoder.layers.3.self_attn.out_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.3.self_attn.out_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.3.norm2.weight\": 256,\n",
            "  \"transformer.decoder.layers.3.norm2.bias\": 256,\n",
            "  \"transformer.decoder.layers.3.linear1.weight\": 524288,\n",
            "  \"transformer.decoder.layers.3.linear1.bias\": 2048,\n",
            "  \"transformer.decoder.layers.3.linear2.weight\": 524288,\n",
            "  \"transformer.decoder.layers.3.linear2.bias\": 256,\n",
            "  \"transformer.decoder.layers.3.norm3.weight\": 256,\n",
            "  \"transformer.decoder.layers.3.norm3.bias\": 256,\n",
            "  \"transformer.decoder.layers.4.cross_attn.sampling_offsets.weight\": 65536,\n",
            "  \"transformer.decoder.layers.4.cross_attn.sampling_offsets.bias\": 256,\n",
            "  \"transformer.decoder.layers.4.cross_attn.attention_weights.weight\": 32768,\n",
            "  \"transformer.decoder.layers.4.cross_attn.attention_weights.bias\": 128,\n",
            "  \"transformer.decoder.layers.4.cross_attn.value_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.4.cross_attn.value_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.4.cross_attn.output_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.4.cross_attn.output_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.4.norm1.weight\": 256,\n",
            "  \"transformer.decoder.layers.4.norm1.bias\": 256,\n",
            "  \"transformer.decoder.layers.4.ca_text.in_proj_weight\": 196608,\n",
            "  \"transformer.decoder.layers.4.ca_text.in_proj_bias\": 768,\n",
            "  \"transformer.decoder.layers.4.ca_text.out_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.4.ca_text.out_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.4.catext_norm.weight\": 256,\n",
            "  \"transformer.decoder.layers.4.catext_norm.bias\": 256,\n",
            "  \"transformer.decoder.layers.4.self_attn.in_proj_weight\": 196608,\n",
            "  \"transformer.decoder.layers.4.self_attn.in_proj_bias\": 768,\n",
            "  \"transformer.decoder.layers.4.self_attn.out_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.4.self_attn.out_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.4.norm2.weight\": 256,\n",
            "  \"transformer.decoder.layers.4.norm2.bias\": 256,\n",
            "  \"transformer.decoder.layers.4.linear1.weight\": 524288,\n",
            "  \"transformer.decoder.layers.4.linear1.bias\": 2048,\n",
            "  \"transformer.decoder.layers.4.linear2.weight\": 524288,\n",
            "  \"transformer.decoder.layers.4.linear2.bias\": 256,\n",
            "  \"transformer.decoder.layers.4.norm3.weight\": 256,\n",
            "  \"transformer.decoder.layers.4.norm3.bias\": 256,\n",
            "  \"transformer.decoder.layers.5.cross_attn.sampling_offsets.weight\": 65536,\n",
            "  \"transformer.decoder.layers.5.cross_attn.sampling_offsets.bias\": 256,\n",
            "  \"transformer.decoder.layers.5.cross_attn.attention_weights.weight\": 32768,\n",
            "  \"transformer.decoder.layers.5.cross_attn.attention_weights.bias\": 128,\n",
            "  \"transformer.decoder.layers.5.cross_attn.value_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.5.cross_attn.value_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.5.cross_attn.output_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.5.cross_attn.output_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.5.norm1.weight\": 256,\n",
            "  \"transformer.decoder.layers.5.norm1.bias\": 256,\n",
            "  \"transformer.decoder.layers.5.ca_text.in_proj_weight\": 196608,\n",
            "  \"transformer.decoder.layers.5.ca_text.in_proj_bias\": 768,\n",
            "  \"transformer.decoder.layers.5.ca_text.out_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.5.ca_text.out_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.5.catext_norm.weight\": 256,\n",
            "  \"transformer.decoder.layers.5.catext_norm.bias\": 256,\n",
            "  \"transformer.decoder.layers.5.self_attn.in_proj_weight\": 196608,\n",
            "  \"transformer.decoder.layers.5.self_attn.in_proj_bias\": 768,\n",
            "  \"transformer.decoder.layers.5.self_attn.out_proj.weight\": 65536,\n",
            "  \"transformer.decoder.layers.5.self_attn.out_proj.bias\": 256,\n",
            "  \"transformer.decoder.layers.5.norm2.weight\": 256,\n",
            "  \"transformer.decoder.layers.5.norm2.bias\": 256,\n",
            "  \"transformer.decoder.layers.5.linear1.weight\": 524288,\n",
            "  \"transformer.decoder.layers.5.linear1.bias\": 2048,\n",
            "  \"transformer.decoder.layers.5.linear2.weight\": 524288,\n",
            "  \"transformer.decoder.layers.5.linear2.bias\": 256,\n",
            "  \"transformer.decoder.layers.5.norm3.weight\": 256,\n",
            "  \"transformer.decoder.layers.5.norm3.bias\": 256,\n",
            "  \"transformer.decoder.norm.weight\": 256,\n",
            "  \"transformer.decoder.norm.bias\": 256,\n",
            "  \"transformer.decoder.ref_point_head.layers.0.weight\": 131072,\n",
            "  \"transformer.decoder.ref_point_head.layers.0.bias\": 256,\n",
            "  \"transformer.decoder.ref_point_head.layers.1.weight\": 65536,\n",
            "  \"transformer.decoder.ref_point_head.layers.1.bias\": 256,\n",
            "  \"transformer.decoder.bbox_embed.0.layers.0.weight\": 65536,\n",
            "  \"transformer.decoder.bbox_embed.0.layers.0.bias\": 256,\n",
            "  \"transformer.decoder.bbox_embed.0.layers.1.weight\": 65536,\n",
            "  \"transformer.decoder.bbox_embed.0.layers.1.bias\": 256,\n",
            "  \"transformer.decoder.bbox_embed.0.layers.2.weight\": 1024,\n",
            "  \"transformer.decoder.bbox_embed.0.layers.2.bias\": 4,\n",
            "  \"transformer.tgt_embed.weight\": 230400,\n",
            "  \"transformer.enc_output.weight\": 65536,\n",
            "  \"transformer.enc_output.bias\": 256,\n",
            "  \"transformer.enc_output_norm.weight\": 256,\n",
            "  \"transformer.enc_output_norm.bias\": 256,\n",
            "  \"transformer.enc_out_bbox_embed.layers.0.weight\": 65536,\n",
            "  \"transformer.enc_out_bbox_embed.layers.0.bias\": 256,\n",
            "  \"transformer.enc_out_bbox_embed.layers.1.weight\": 65536,\n",
            "  \"transformer.enc_out_bbox_embed.layers.1.bias\": 256,\n",
            "  \"transformer.enc_out_bbox_embed.layers.2.weight\": 1024,\n",
            "  \"transformer.enc_out_bbox_embed.layers.2.bias\": 4,\n",
            "  \"feat_map.weight\": 196608,\n",
            "  \"feat_map.bias\": 256,\n",
            "  \"input_proj.0.0.weight\": 49152,\n",
            "  \"input_proj.0.0.bias\": 256,\n",
            "  \"input_proj.0.1.weight\": 256,\n",
            "  \"input_proj.0.1.bias\": 256,\n",
            "  \"input_proj.1.0.weight\": 98304,\n",
            "  \"input_proj.1.0.bias\": 256,\n",
            "  \"input_proj.1.1.weight\": 256,\n",
            "  \"input_proj.1.1.bias\": 256,\n",
            "  \"input_proj.2.0.weight\": 196608,\n",
            "  \"input_proj.2.0.bias\": 256,\n",
            "  \"input_proj.2.1.weight\": 256,\n",
            "  \"input_proj.2.1.bias\": 256,\n",
            "  \"input_proj.3.0.weight\": 1769472,\n",
            "  \"input_proj.3.0.bias\": 256,\n",
            "  \"input_proj.3.1.weight\": 256,\n",
            "  \"input_proj.3.1.bias\": 256,\n",
            "  \"backbone.0.patch_embed.proj.weight\": 4608,\n",
            "  \"backbone.0.patch_embed.proj.bias\": 96,\n",
            "  \"backbone.0.patch_embed.norm.weight\": 96,\n",
            "  \"backbone.0.patch_embed.norm.bias\": 96,\n",
            "  \"backbone.0.layers.0.blocks.0.norm1.weight\": 96,\n",
            "  \"backbone.0.layers.0.blocks.0.norm1.bias\": 96,\n",
            "  \"backbone.0.layers.0.blocks.0.attn.relative_position_bias_table\": 507,\n",
            "  \"backbone.0.layers.0.blocks.0.attn.qkv.weight\": 27648,\n",
            "  \"backbone.0.layers.0.blocks.0.attn.qkv.bias\": 288,\n",
            "  \"backbone.0.layers.0.blocks.0.attn.proj.weight\": 9216,\n",
            "  \"backbone.0.layers.0.blocks.0.attn.proj.bias\": 96,\n",
            "  \"backbone.0.layers.0.blocks.0.norm2.weight\": 96,\n",
            "  \"backbone.0.layers.0.blocks.0.norm2.bias\": 96,\n",
            "  \"backbone.0.layers.0.blocks.0.mlp.fc1.weight\": 36864,\n",
            "  \"backbone.0.layers.0.blocks.0.mlp.fc1.bias\": 384,\n",
            "  \"backbone.0.layers.0.blocks.0.mlp.fc2.weight\": 36864,\n",
            "  \"backbone.0.layers.0.blocks.0.mlp.fc2.bias\": 96,\n",
            "  \"backbone.0.layers.0.blocks.1.norm1.weight\": 96,\n",
            "  \"backbone.0.layers.0.blocks.1.norm1.bias\": 96,\n",
            "  \"backbone.0.layers.0.blocks.1.attn.relative_position_bias_table\": 507,\n",
            "  \"backbone.0.layers.0.blocks.1.attn.qkv.weight\": 27648,\n",
            "  \"backbone.0.layers.0.blocks.1.attn.qkv.bias\": 288,\n",
            "  \"backbone.0.layers.0.blocks.1.attn.proj.weight\": 9216,\n",
            "  \"backbone.0.layers.0.blocks.1.attn.proj.bias\": 96,\n",
            "  \"backbone.0.layers.0.blocks.1.norm2.weight\": 96,\n",
            "  \"backbone.0.layers.0.blocks.1.norm2.bias\": 96,\n",
            "  \"backbone.0.layers.0.blocks.1.mlp.fc1.weight\": 36864,\n",
            "  \"backbone.0.layers.0.blocks.1.mlp.fc1.bias\": 384,\n",
            "  \"backbone.0.layers.0.blocks.1.mlp.fc2.weight\": 36864,\n",
            "  \"backbone.0.layers.0.blocks.1.mlp.fc2.bias\": 96,\n",
            "  \"backbone.0.layers.0.downsample.reduction.weight\": 73728,\n",
            "  \"backbone.0.layers.0.downsample.norm.weight\": 384,\n",
            "  \"backbone.0.layers.0.downsample.norm.bias\": 384,\n",
            "  \"backbone.0.layers.1.blocks.0.norm1.weight\": 192,\n",
            "  \"backbone.0.layers.1.blocks.0.norm1.bias\": 192,\n",
            "  \"backbone.0.layers.1.blocks.0.attn.relative_position_bias_table\": 1014,\n",
            "  \"backbone.0.layers.1.blocks.0.attn.qkv.weight\": 110592,\n",
            "  \"backbone.0.layers.1.blocks.0.attn.qkv.bias\": 576,\n",
            "  \"backbone.0.layers.1.blocks.0.attn.proj.weight\": 36864,\n",
            "  \"backbone.0.layers.1.blocks.0.attn.proj.bias\": 192,\n",
            "  \"backbone.0.layers.1.blocks.0.norm2.weight\": 192,\n",
            "  \"backbone.0.layers.1.blocks.0.norm2.bias\": 192,\n",
            "  \"backbone.0.layers.1.blocks.0.mlp.fc1.weight\": 147456,\n",
            "  \"backbone.0.layers.1.blocks.0.mlp.fc1.bias\": 768,\n",
            "  \"backbone.0.layers.1.blocks.0.mlp.fc2.weight\": 147456,\n",
            "  \"backbone.0.layers.1.blocks.0.mlp.fc2.bias\": 192,\n",
            "  \"backbone.0.layers.1.blocks.1.norm1.weight\": 192,\n",
            "  \"backbone.0.layers.1.blocks.1.norm1.bias\": 192,\n",
            "  \"backbone.0.layers.1.blocks.1.attn.relative_position_bias_table\": 1014,\n",
            "  \"backbone.0.layers.1.blocks.1.attn.qkv.weight\": 110592,\n",
            "  \"backbone.0.layers.1.blocks.1.attn.qkv.bias\": 576,\n",
            "  \"backbone.0.layers.1.blocks.1.attn.proj.weight\": 36864,\n",
            "  \"backbone.0.layers.1.blocks.1.attn.proj.bias\": 192,\n",
            "  \"backbone.0.layers.1.blocks.1.norm2.weight\": 192,\n",
            "  \"backbone.0.layers.1.blocks.1.norm2.bias\": 192,\n",
            "  \"backbone.0.layers.1.blocks.1.mlp.fc1.weight\": 147456,\n",
            "  \"backbone.0.layers.1.blocks.1.mlp.fc1.bias\": 768,\n",
            "  \"backbone.0.layers.1.blocks.1.mlp.fc2.weight\": 147456,\n",
            "  \"backbone.0.layers.1.blocks.1.mlp.fc2.bias\": 192,\n",
            "  \"backbone.0.layers.1.downsample.reduction.weight\": 294912,\n",
            "  \"backbone.0.layers.1.downsample.norm.weight\": 768,\n",
            "  \"backbone.0.layers.1.downsample.norm.bias\": 768,\n",
            "  \"backbone.0.layers.2.blocks.0.norm1.weight\": 384,\n",
            "  \"backbone.0.layers.2.blocks.0.norm1.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.0.attn.relative_position_bias_table\": 2028,\n",
            "  \"backbone.0.layers.2.blocks.0.attn.qkv.weight\": 442368,\n",
            "  \"backbone.0.layers.2.blocks.0.attn.qkv.bias\": 1152,\n",
            "  \"backbone.0.layers.2.blocks.0.attn.proj.weight\": 147456,\n",
            "  \"backbone.0.layers.2.blocks.0.attn.proj.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.0.norm2.weight\": 384,\n",
            "  \"backbone.0.layers.2.blocks.0.norm2.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.0.mlp.fc1.weight\": 589824,\n",
            "  \"backbone.0.layers.2.blocks.0.mlp.fc1.bias\": 1536,\n",
            "  \"backbone.0.layers.2.blocks.0.mlp.fc2.weight\": 589824,\n",
            "  \"backbone.0.layers.2.blocks.0.mlp.fc2.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.1.norm1.weight\": 384,\n",
            "  \"backbone.0.layers.2.blocks.1.norm1.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.1.attn.relative_position_bias_table\": 2028,\n",
            "  \"backbone.0.layers.2.blocks.1.attn.qkv.weight\": 442368,\n",
            "  \"backbone.0.layers.2.blocks.1.attn.qkv.bias\": 1152,\n",
            "  \"backbone.0.layers.2.blocks.1.attn.proj.weight\": 147456,\n",
            "  \"backbone.0.layers.2.blocks.1.attn.proj.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.1.norm2.weight\": 384,\n",
            "  \"backbone.0.layers.2.blocks.1.norm2.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.1.mlp.fc1.weight\": 589824,\n",
            "  \"backbone.0.layers.2.blocks.1.mlp.fc1.bias\": 1536,\n",
            "  \"backbone.0.layers.2.blocks.1.mlp.fc2.weight\": 589824,\n",
            "  \"backbone.0.layers.2.blocks.1.mlp.fc2.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.2.norm1.weight\": 384,\n",
            "  \"backbone.0.layers.2.blocks.2.norm1.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.2.attn.relative_position_bias_table\": 2028,\n",
            "  \"backbone.0.layers.2.blocks.2.attn.qkv.weight\": 442368,\n",
            "  \"backbone.0.layers.2.blocks.2.attn.qkv.bias\": 1152,\n",
            "  \"backbone.0.layers.2.blocks.2.attn.proj.weight\": 147456,\n",
            "  \"backbone.0.layers.2.blocks.2.attn.proj.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.2.norm2.weight\": 384,\n",
            "  \"backbone.0.layers.2.blocks.2.norm2.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.2.mlp.fc1.weight\": 589824,\n",
            "  \"backbone.0.layers.2.blocks.2.mlp.fc1.bias\": 1536,\n",
            "  \"backbone.0.layers.2.blocks.2.mlp.fc2.weight\": 589824,\n",
            "  \"backbone.0.layers.2.blocks.2.mlp.fc2.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.3.norm1.weight\": 384,\n",
            "  \"backbone.0.layers.2.blocks.3.norm1.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.3.attn.relative_position_bias_table\": 2028,\n",
            "  \"backbone.0.layers.2.blocks.3.attn.qkv.weight\": 442368,\n",
            "  \"backbone.0.layers.2.blocks.3.attn.qkv.bias\": 1152,\n",
            "  \"backbone.0.layers.2.blocks.3.attn.proj.weight\": 147456,\n",
            "  \"backbone.0.layers.2.blocks.3.attn.proj.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.3.norm2.weight\": 384,\n",
            "  \"backbone.0.layers.2.blocks.3.norm2.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.3.mlp.fc1.weight\": 589824,\n",
            "  \"backbone.0.layers.2.blocks.3.mlp.fc1.bias\": 1536,\n",
            "  \"backbone.0.layers.2.blocks.3.mlp.fc2.weight\": 589824,\n",
            "  \"backbone.0.layers.2.blocks.3.mlp.fc2.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.4.norm1.weight\": 384,\n",
            "  \"backbone.0.layers.2.blocks.4.norm1.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.4.attn.relative_position_bias_table\": 2028,\n",
            "  \"backbone.0.layers.2.blocks.4.attn.qkv.weight\": 442368,\n",
            "  \"backbone.0.layers.2.blocks.4.attn.qkv.bias\": 1152,\n",
            "  \"backbone.0.layers.2.blocks.4.attn.proj.weight\": 147456,\n",
            "  \"backbone.0.layers.2.blocks.4.attn.proj.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.4.norm2.weight\": 384,\n",
            "  \"backbone.0.layers.2.blocks.4.norm2.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.4.mlp.fc1.weight\": 589824,\n",
            "  \"backbone.0.layers.2.blocks.4.mlp.fc1.bias\": 1536,\n",
            "  \"backbone.0.layers.2.blocks.4.mlp.fc2.weight\": 589824,\n",
            "  \"backbone.0.layers.2.blocks.4.mlp.fc2.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.5.norm1.weight\": 384,\n",
            "  \"backbone.0.layers.2.blocks.5.norm1.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.5.attn.relative_position_bias_table\": 2028,\n",
            "  \"backbone.0.layers.2.blocks.5.attn.qkv.weight\": 442368,\n",
            "  \"backbone.0.layers.2.blocks.5.attn.qkv.bias\": 1152,\n",
            "  \"backbone.0.layers.2.blocks.5.attn.proj.weight\": 147456,\n",
            "  \"backbone.0.layers.2.blocks.5.attn.proj.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.5.norm2.weight\": 384,\n",
            "  \"backbone.0.layers.2.blocks.5.norm2.bias\": 384,\n",
            "  \"backbone.0.layers.2.blocks.5.mlp.fc1.weight\": 589824,\n",
            "  \"backbone.0.layers.2.blocks.5.mlp.fc1.bias\": 1536,\n",
            "  \"backbone.0.layers.2.blocks.5.mlp.fc2.weight\": 589824,\n",
            "  \"backbone.0.layers.2.blocks.5.mlp.fc2.bias\": 384,\n",
            "  \"backbone.0.layers.2.downsample.reduction.weight\": 1179648,\n",
            "  \"backbone.0.layers.2.downsample.norm.weight\": 1536,\n",
            "  \"backbone.0.layers.2.downsample.norm.bias\": 1536,\n",
            "  \"backbone.0.layers.3.blocks.0.norm1.weight\": 768,\n",
            "  \"backbone.0.layers.3.blocks.0.norm1.bias\": 768,\n",
            "  \"backbone.0.layers.3.blocks.0.attn.relative_position_bias_table\": 4056,\n",
            "  \"backbone.0.layers.3.blocks.0.attn.qkv.weight\": 1769472,\n",
            "  \"backbone.0.layers.3.blocks.0.attn.qkv.bias\": 2304,\n",
            "  \"backbone.0.layers.3.blocks.0.attn.proj.weight\": 589824,\n",
            "  \"backbone.0.layers.3.blocks.0.attn.proj.bias\": 768,\n",
            "  \"backbone.0.layers.3.blocks.0.norm2.weight\": 768,\n",
            "  \"backbone.0.layers.3.blocks.0.norm2.bias\": 768,\n",
            "  \"backbone.0.layers.3.blocks.0.mlp.fc1.weight\": 2359296,\n",
            "  \"backbone.0.layers.3.blocks.0.mlp.fc1.bias\": 3072,\n",
            "  \"backbone.0.layers.3.blocks.0.mlp.fc2.weight\": 2359296,\n",
            "  \"backbone.0.layers.3.blocks.0.mlp.fc2.bias\": 768,\n",
            "  \"backbone.0.layers.3.blocks.1.norm1.weight\": 768,\n",
            "  \"backbone.0.layers.3.blocks.1.norm1.bias\": 768,\n",
            "  \"backbone.0.layers.3.blocks.1.attn.relative_position_bias_table\": 4056,\n",
            "  \"backbone.0.layers.3.blocks.1.attn.qkv.weight\": 1769472,\n",
            "  \"backbone.0.layers.3.blocks.1.attn.qkv.bias\": 2304,\n",
            "  \"backbone.0.layers.3.blocks.1.attn.proj.weight\": 589824,\n",
            "  \"backbone.0.layers.3.blocks.1.attn.proj.bias\": 768,\n",
            "  \"backbone.0.layers.3.blocks.1.norm2.weight\": 768,\n",
            "  \"backbone.0.layers.3.blocks.1.norm2.bias\": 768,\n",
            "  \"backbone.0.layers.3.blocks.1.mlp.fc1.weight\": 2359296,\n",
            "  \"backbone.0.layers.3.blocks.1.mlp.fc1.bias\": 3072,\n",
            "  \"backbone.0.layers.3.blocks.1.mlp.fc2.weight\": 2359296,\n",
            "  \"backbone.0.layers.3.blocks.1.mlp.fc2.bias\": 768,\n",
            "  \"backbone.0.norm1.weight\": 192,\n",
            "  \"backbone.0.norm1.bias\": 192,\n",
            "  \"backbone.0.norm2.weight\": 384,\n",
            "  \"backbone.0.norm2.bias\": 384,\n",
            "  \"backbone.0.norm3.weight\": 768,\n",
            "  \"backbone.0.norm3.bias\": 768\n",
            "}\u001b[0m\n",
            "\u001b[36mDEBUG   \u001b[0m \u001b[36m2023-12-14 08:07:53,548 | \u001b[34mbuild dataset ... ...\u001b[0m\n",
            "figs/train config/odvg.json config/label.json\n",
            "  == total images: 403\n",
            "  == total labels: 10\n",
            "\u001b[36mDEBUG   \u001b[0m \u001b[36m2023-12-14 08:07:53,553 | \u001b[34mbuild dataset, done.\u001b[0m\n",
            "\u001b[36mDEBUG   \u001b[0m \u001b[36m2023-12-14 08:07:53,553 | \u001b[34mnumber of training dataset: 1, samples: 403\u001b[0m\n",
            "figs/valid config/Val2.json\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\u001b[32mINFO    \u001b[0m \u001b[32m2023-12-14 08:08:02,218 | \u001b[34mIgnore keys: []\u001b[0m\n",
            "\u001b[32mINFO    \u001b[0m \u001b[32m2023-12-14 08:08:02,454 | \u001b[34m_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\u001b[0m\n",
            "Start training\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:907: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "Epoch: [0]  [ 0/57]  eta: 0:07:23  lr: 0.000100  loss: 54.0607 (54.0607)  loss_ce: 4.9496 (4.9496)  loss_bbox: 1.1360 (1.1360)  loss_giou: 1.6258 (1.6258)  loss_ce_0: 4.8426 (4.8426)  loss_bbox_0: 1.1641 (1.1641)  loss_giou_0: 1.7764 (1.7764)  loss_ce_1: 4.8327 (4.8327)  loss_bbox_1: 1.2627 (1.2627)  loss_giou_1: 1.7189 (1.7189)  loss_ce_2: 4.8150 (4.8150)  loss_bbox_2: 1.1880 (1.1880)  loss_giou_2: 1.6564 (1.6564)  loss_ce_3: 4.8963 (4.8963)  loss_bbox_3: 1.1794 (1.1794)  loss_giou_3: 1.6359 (1.6359)  loss_ce_4: 4.8335 (4.8335)  loss_bbox_4: 1.1313 (1.1313)  loss_giou_4: 1.6354 (1.6354)  loss_ce_interm: 4.5466 (4.5466)  loss_bbox_interm: 1.3165 (1.3165)  loss_giou_interm: 1.9175 (1.9175)  loss_ce_unscaled: 2.4748 (2.4748)  loss_bbox_unscaled: 0.2272 (0.2272)  loss_giou_unscaled: 0.8129 (0.8129)  loss_xy_unscaled: 0.0930 (0.0930)  loss_hw_unscaled: 0.1342 (0.1342)  loss_ce_0_unscaled: 2.4213 (2.4213)  loss_bbox_0_unscaled: 0.2328 (0.2328)  loss_giou_0_unscaled: 0.8882 (0.8882)  loss_xy_0_unscaled: 0.1047 (0.1047)  loss_hw_0_unscaled: 0.1282 (0.1282)  loss_ce_1_unscaled: 2.4163 (2.4163)  loss_bbox_1_unscaled: 0.2525 (0.2525)  loss_giou_1_unscaled: 0.8594 (0.8594)  loss_xy_1_unscaled: 0.1096 (0.1096)  loss_hw_1_unscaled: 0.1430 (0.1430)  loss_ce_2_unscaled: 2.4075 (2.4075)  loss_bbox_2_unscaled: 0.2376 (0.2376)  loss_giou_2_unscaled: 0.8282 (0.8282)  loss_xy_2_unscaled: 0.1006 (0.1006)  loss_hw_2_unscaled: 0.1370 (0.1370)  loss_ce_3_unscaled: 2.4482 (2.4482)  loss_bbox_3_unscaled: 0.2359 (0.2359)  loss_giou_3_unscaled: 0.8180 (0.8180)  loss_xy_3_unscaled: 0.0938 (0.0938)  loss_hw_3_unscaled: 0.1421 (0.1421)  loss_ce_4_unscaled: 2.4168 (2.4168)  loss_bbox_4_unscaled: 0.2263 (0.2263)  loss_giou_4_unscaled: 0.8177 (0.8177)  loss_xy_4_unscaled: 0.0944 (0.0944)  loss_hw_4_unscaled: 0.1319 (0.1319)  loss_ce_interm_unscaled: 2.2733 (2.2733)  loss_bbox_interm_unscaled: 0.2633 (0.2633)  loss_giou_interm_unscaled: 0.9587 (0.9587)  loss_xy_interm_unscaled: 0.1218 (0.1218)  loss_hw_interm_unscaled: 0.1415 (0.1415)  time: 7.7846  data: 2.1401  max mem: 6725\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Open-GroundingDino/main.py\", line 372, in <module>\n",
            "    main(args)\n",
            "  File \"/content/Open-GroundingDino/main.py\", line 285, in main\n",
            "    train_stats = train_one_epoch(\n",
            "  File \"/content/Open-GroundingDino/engine.py\", line 47, in train_one_epoch\n",
            "    outputs = model(samples, captions=captions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/Open-GroundingDino/models/GroundingDINO/groundingdino.py\", line 246, in forward\n",
            "    ) = generate_masks_with_special_tokens_and_transfer_map(\n",
            "  File \"/content/Open-GroundingDino/models/GroundingDINO/bertwarper.py\", line 261, in generate_masks_with_special_tokens_and_transfer_map\n",
            "    cate_to_token_mask_list[row].append(c2t_maski)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/Open-GroundingDino/logs/checkpoint0003.pth '/content/drive/MyDrive/dino_data/'"
      ],
      "metadata": {
        "id": "0fiiV_6ngK13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kGq6K0WmgY_V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}